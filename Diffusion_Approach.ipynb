{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea7f10f8",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "The goal of this project is to use a diffusion model to generate Shakespeare-like texts or sonnets. Typically, this task is handled by transformer-based models, while diffusion models are primarily used for image or video generation. This is part 1 of my research project, where I compare the outputs of transformer and diffusion models to evaluate how diffusion models can be adapted for tasks beyond image or video generation.\n",
    "\n",
    "## Takeaways from Initial Testing\n",
    "\n",
    "Rather than include all the testing conducted, which would make this notebook unwieldy, I'll summarize the approaches attempted and conclusions reached before arriving at the current implementation.\n",
    "\n",
    "- I started with BERT embeddings, as they're widely used in language generation tasks.\n",
    "\n",
    "- I initially focused on training a custom decoder to revert denoised, contextualized BERT embeddings, as this appeared to be the most challenging aspect of the project.\n",
    "  \n",
    "- A separate decoder learned relatively well when trained on clean BERT embeddings and successfully reverted contextualized embeddings back to their respective words. This was tested at various noise levels with positive results.\n",
    "\n",
    "- My first attempt used SVO (Subject-Verb-Object) structure combined with thematic keywords extracted using spaCy. This was necessary since Shakespeare's archaic language means SVO patterns only cover about 18% of the total lines. I trained a UNET model with an additional projection layer: the projection layer learned the decoding task while the diffuser learned to predict noise levels. This approach failed, producing gibberish output. The reconstruction loss remained too high while the diffusion loss dropped relatively rapidly.\n",
    "  \n",
    "- I then switched to using a frozen pretrained decoder for the same task. This resulted in numerous repeated tokens—what I believe to be the text diffusion equivalent of mode collapse. Rather than exploring various embedding possibilities, the model fell back on the most frequently used tokens.\n",
    "  \n",
    "- This led to the realization that we needed to restructure the dataset and potentially use non-contextualized BERT embeddings. The contextualized embedding space appeared incompatible with Shakespearean text. Furthermore, the frozen embeddings couldn't be adjusted by the reconstruction loss gradients flowing backward. The decoder approach was fundamentally flawed: regardless of weight adjustments, the decoder still had to work with frozen BERT embeddings that couldn't adapt to become more decoder-friendly.\n",
    "\n",
    "### Approach Taken to Address These Bottlenecks\n",
    "\n",
    "- If non-contextualized BERT embeddings could work, we might as well shift to a custom embedding space based solely on our dataset. This would be a simpler lookup table. However, to aid the decoding task, we need a way to backpropagate reconstruction losses to these embeddings. This allows the decoder to learn decoding while the embeddings in our high-dimensional space adjust based on:\n",
    "  - A) The primary task of predicting noise to arrive at a token\n",
    "  - B) The auxiliary task of making themselves decoder-friendly (given an effective decoding strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01afa0b",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b665f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from diffusers import DDPMScheduler, DDIMScheduler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1842cf0f",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e5049",
   "metadata": {},
   "source": [
    "Let us load the dataset and parse them into individual lines. We build  dictionaries (word to idx/ idx to word) for all unique words as well as  special tokens that denote padding, line start/end and unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715df564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2185 lines\n",
      "Vocabulary size: 3432\n",
      "Most common words: [(',', 1635), ('.', 546), ('and', 495), ('the', 436), ('to', 414), ('my', 374), ('of', 372), ('i', 350), ('that', 329), ('in', 328)]\n",
      "Special tokens: ['<PAD>', '<UNK>', '<START>', '<END>']\n"
     ]
    }
   ],
   "source": [
    "# Load Shakespeare sonnets\n",
    "data_path = Path('data/shakespeare-sonnets.txt')\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    sonnets_raw = f.read()\n",
    "\n",
    "# Parse into lines\n",
    "lines = []\n",
    "for line in sonnets_raw.split('\\n'):\n",
    "    line = line.strip()\n",
    "    if line and not line.isdigit() and not line.startswith('Sonnet'):\n",
    "        lines.append(line)\n",
    "\n",
    "print(f\"Loaded {len(lines)} lines\")\n",
    "\n",
    "# Build vocabulary from all words\n",
    "word_counter = Counter()\n",
    "for line in lines:\n",
    "    # Simple whitespace tokenization, lowercase\n",
    "    words = line.lower().replace(',', ' ,').replace('.', ' .').replace('!', ' !').replace('?', ' ?').split()\n",
    "    word_counter.update(words)\n",
    "\n",
    "# Create vocabulary with special tokens\n",
    "special_tokens = ['<PAD>', '<UNK>', '<START>', '<END>']\n",
    "vocab = special_tokens + [word for word, count in word_counter.most_common()]\n",
    "\n",
    "# Create word→ID and ID→word mappings\n",
    "word2id = {word: idx for idx, word in enumerate(vocab)}\n",
    "id2word = {idx: word for word, idx in word2id.items()}\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Most common words: {list(word_counter.most_common(10))}\")\n",
    "print(f\"Special tokens: {special_tokens}\")\n",
    "\n",
    "# Define special token IDs\n",
    "PAD_ID = word2id['<PAD>']\n",
    "UNK_ID = word2id['<UNK>']\n",
    "START_ID = word2id['<START>']\n",
    "END_ID = word2id['<END>']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b3774",
   "metadata": {},
   "source": [
    "The usual SVO pair structural control fails for archaic lines. So we will go with just a start word, a middle word and an end word to each sentence that can help us guide the model on filling in the gaps with grammatically sound phrases. \n",
    "\n",
    "We extract these triplets from each sentence and append it to our dataset as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e806c01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting conditioning: 100%|██████████| 2185/2185 [00:00<00:00, 247229.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 2183 samples\n",
      "1. From fairest creatures we desire increase,...\n",
      "   first='from' middle='we' last='increase' count=6\n",
      "2. That thereby beauty's rose might never die,...\n",
      "   first='that' middle='rose' last='die' count=7\n",
      "3. But, as the riper should by time decease,...\n",
      "   first='but' middle='should' last='decease' count=8\n",
      "4. His tender heir might bear his memory....\n",
      "   first='his' middle='might' last='memory' count=7\n",
      "5. But thou, contracted to thine own bright eyes,...\n",
      "   first='but' middle='thine' last='eyes' count=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_positional_triplet(line, word2id):\n",
    "    \"\"\"\n",
    "    Extract first, middle, and last content words from line.\n",
    "    Returns token IDs and word count.\n",
    "    \"\"\"\n",
    "    # Tokenize: split and clean\n",
    "    words = line.lower().replace(',', ' ,').replace('.', ' .').replace('!', ' !').replace('?', ' ?').split()\n",
    "    \n",
    "    # Remove punctuation-only tokens for conditioning\n",
    "    content_words = []\n",
    "    for word in words:\n",
    "        word_clean = word.strip('.,!?;:\\'\"')\n",
    "        if len(word_clean) > 1:\n",
    "            content_words.append(word_clean)\n",
    "    \n",
    "    if len(content_words) < 3:\n",
    "        return None\n",
    "    \n",
    "    first_word = content_words[0]\n",
    "    middle_word = content_words[len(content_words) // 2]\n",
    "    last_word = content_words[-1]\n",
    "    \n",
    "    # Convert to IDs (use UNK for unknown words)\n",
    "    first_id = word2id.get(first_word, UNK_ID)\n",
    "    middle_id = word2id.get(middle_word, UNK_ID)\n",
    "    last_id = word2id.get(last_word, UNK_ID)\n",
    "    \n",
    "    return {\n",
    "        'first_id': first_id,\n",
    "        'middle_id': middle_id,\n",
    "        'last_id': last_id,\n",
    "        'word_count': len(content_words),\n",
    "        'words': words  # Full tokenized line\n",
    "    }\n",
    "\n",
    "# Extract conditioning for all lines\n",
    "dataset = []\n",
    "\n",
    "for line in tqdm(lines, desc=\"Extracting conditioning\"):\n",
    "    triplet = extract_positional_triplet(line, word2id)\n",
    "    \n",
    "    if triplet:\n",
    "        dataset.append({\n",
    "            'line': line,\n",
    "            'words': triplet['words'],\n",
    "            'first_id': triplet['first_id'],\n",
    "            'middle_id': triplet['middle_id'],\n",
    "            'last_id': triplet['last_id'],\n",
    "            'word_count': triplet['word_count']\n",
    "        })\n",
    "\n",
    "print(f\"Dataset: {len(dataset)} samples\")\n",
    "\n",
    "# Verify\n",
    "for i in range(5):\n",
    "    d = dataset[i]\n",
    "    first = id2word[d['first_id']]\n",
    "    middle = id2word[d['middle_id']]\n",
    "    last = id2word[d['last_id']]\n",
    "    print(f\"{i+1}. {d['line'][:50]}...\")\n",
    "    print(f\"   first='{first}' middle='{middle}' last='{last}' count={d['word_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de99af",
   "metadata": {},
   "source": [
    "Let us run a quick check on if we have caught any UNK tokens in our triplets. This could be possible as archaic words like feed'st might be post-processed to gibberish tokens because of the stripped qoutation mark.\n",
    "\n",
    "We visualize and check for if the first five sentences map to our triplets coherently before checking word count distribution across all lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ebb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting conditioning: 100%|██████████| 2185/2185 [00:00<00:00, 242956.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: 2183 samples from 2185 lines\n",
      "\n",
      "SANITY CHECK 1: First 5 samples\n",
      "======================================================================\n",
      "1. From fairest creatures we desire increase,...\n",
      "   Triplet: first='from' middle='we' last='increase'\n",
      "   Count: 6 words\n",
      "2. That thereby beauty's rose might never die,...\n",
      "   Triplet: first='that' middle='rose' last='die'\n",
      "   Count: 7 words\n",
      "3. But, as the riper should by time decease,...\n",
      "   Triplet: first='but' middle='should' last='decease'\n",
      "   Count: 8 words\n",
      "4. His tender heir might bear his memory....\n",
      "   Triplet: first='his' middle='might' last='memory'\n",
      "   Count: 7 words\n",
      "5. But thou, contracted to thine own bright eyes,...\n",
      "   Triplet: first='but' middle='thine' last='eyes'\n",
      "   Count: 8 words\n",
      "\n",
      "SANITY CHECK 2: Unknown tokens in conditioning\n",
      "  Samples with <UNK> in triplet: 72/2183\n",
      "  Expected: 0 (all words should be in vocab)\n",
      "\n",
      "SANITY CHECK 3: Word count distribution\n",
      "  Min: 4, Max: 11, Mean: 7.9\n",
      "  Expected: Min~5, Max~12, Mean~8\n",
      "\n",
      "If all checks pass, proceed to next cell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify extraction quality\n",
    "print(f\"\\nSANITY CHECK 1: First 5 samples\")\n",
    "print(\"=\"*70)\n",
    "for i in range(5):\n",
    "    d = dataset[i]\n",
    "    first = id2word[d['first_id']]\n",
    "    middle = id2word[d['middle_id']]\n",
    "    last = id2word[d['last_id']]\n",
    "    print(f\"{i+1}. {d['line'][:50]}...\")\n",
    "    print(f\"   Triplet: first='{first}' middle='{middle}' last='{last}'\")\n",
    "    print(f\"   Count: {d['word_count']} words\")\n",
    "\n",
    "# Verify no UNK tokens in conditioning\n",
    "unk_count = sum(1 for d in dataset if UNK_ID in [d['first_id'], d['middle_id'], d['last_id']])\n",
    "print(f\"\\nSANITY CHECK 2: Unknown tokens in conditioning\")\n",
    "print(f\"  Samples with <UNK> in triplet: {unk_count}/{len(dataset)}\")\n",
    "print(f\"  Expected: 0 (all words should be in vocab)\")\n",
    "\n",
    "# Word count distribution\n",
    "word_counts = [d['word_count'] for d in dataset]\n",
    "print(f\"\\nSANITY CHECK 3: Word count distribution\")\n",
    "print(f\"  Min: {min(word_counts)}, Max: {max(word_counts)}, Mean: {np.mean(word_counts):.1f}\")\n",
    "print(f\"  Expected: Min~5, Max~12, Mean~8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00df400",
   "metadata": {},
   "source": [
    "For our embedding that is fed to the model, we have the following conditioning parameters:\n",
    "- text embedding \n",
    "- first word (from look up) \n",
    "- middle word (from look up)\n",
    "- last word (from look up)\n",
    "- whole line (from look up)\n",
    "- word count embedding\n",
    "\n",
    "Our dataset classbelow stores the index values for each of the above mentioned conditioning parameters. We initiate this class, create a dataset and feed it to a dataloader to generate batches.\n",
    "\n",
    "Also note that we keep track of the PAD_ID wherever applied so as to let our embedding layer know later on to ignore these tokens during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e4b4d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset: 2183 samples\n",
      "Dataset ready: 2183 samples\n",
      "Dataloader: 69 batches\n",
      "\n",
      "SANITY CHECK: Token ID ranges\n",
      "  Min ID: 0\n",
      "  Max ID: 3308\n",
      "  Vocab size: 3432\n",
      "  Expected: Min=0, Max<3432\n"
     ]
    }
   ],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset returning token IDs and conditioning IDs.\n",
    "    Embeddings will be learned during training, not pre-computed.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, word2id, max_length=20):\n",
    "        self.data = data\n",
    "        self.word2id = word2id\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        print(f\"Creating dataset: {len(data)} samples\")\n",
    "        \n",
    "        self.token_ids = []\n",
    "        self.first_ids = []\n",
    "        self.middle_ids = []\n",
    "        self.last_ids = []\n",
    "        self.word_counts = []\n",
    "        \n",
    "        for item in data:\n",
    "            # Convert words to IDs\n",
    "            ids = [word2id.get(word, UNK_ID) for word in item['words']]\n",
    "            \n",
    "            # Pad or truncate to max_length\n",
    "            if len(ids) < max_length:\n",
    "                ids = ids + [PAD_ID] * (max_length - len(ids))\n",
    "            else:\n",
    "                ids = ids[:max_length]\n",
    "            \n",
    "            self.token_ids.append(torch.tensor(ids, dtype=torch.long))\n",
    "            self.first_ids.append(item['first_id'])\n",
    "            self.middle_ids.append(item['middle_id'])\n",
    "            self.last_ids.append(item['last_id'])\n",
    "            self.word_counts.append(item['word_count'])\n",
    "        \n",
    "        print(f\"Dataset ready: {len(self.token_ids)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.token_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'token_ids': self.token_ids[idx],\n",
    "            'first_id': self.first_ids[idx],\n",
    "            'middle_id': self.middle_ids[idx],\n",
    "            'last_id': self.last_ids[idx],\n",
    "            'word_count': self.word_counts[idx]\n",
    "        }\n",
    "\n",
    "# Create dataset\n",
    "shakespeare_dataset = ShakespeareDataset(dataset, word2id, max_length=20)\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(shakespeare_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Dataloader: {len(dataloader)} batches\")\n",
    "\n",
    "# SANITY CHECK: Verify token ID ranges\n",
    "sample_batch = next(iter(dataloader))\n",
    "print(f\"\\nSANITY CHECK: Token ID ranges\")\n",
    "print(f\"  Min ID: {sample_batch['token_ids'].min().item()}\")\n",
    "print(f\"  Max ID: {sample_batch['token_ids'].max().item()}\")\n",
    "print(f\"  Vocab size: {vocab_size}\")\n",
    "print(f\"  Expected: Min=0, Max<{vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9413fff7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc91ccf7",
   "metadata": {},
   "source": [
    "## Understanding Weight Tying for Text Decoding\n",
    "\n",
    "Consider an embedded vector (seq, 768). this is an example of a representation derived from our main text embedding space which is of dimension (vocab_size, 768). The text embedding has just as many weights that are malleable and can be trained to shift as per the task our model is trained on.\n",
    "\n",
    "### Text Embedding Weight Matrix Structure\n",
    "\n",
    "- The weights matrix is accessed via text_embeddings.weight [3432, 768]\n",
    "- The transpose of this weight matrix is text_embeddings.weight.T [768, 3432] OR [768, vocab_size]\n",
    "\n",
    "In the weight matrix, each row is a unique word and in its transpose, each column is a unique word. in the case of a vector (seq, 768), each row is a word. \n",
    "\n",
    "### Weight Tying Strategy\n",
    "\n",
    "Our weight_tying strategy is the below operation:\n",
    "```python\n",
    "logits = embedding_vector @ text_embeddings.weight.T\n",
    "```\n",
    "\n",
    "**Dimension breakdown:**\n",
    "- [seq, 768] @ [768, 3432] = [seq, 3432]\n",
    "\n",
    "This translates to (a sequence of words)@(transpose of the text embedding weight matrix)=(scores of every possible word for a given sequence position across all positions of the sequence)\n",
    "\n",
    "for a given seq, we now have probabilities of all possible words at all sequence positions.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Does This Help Us Denoise and Decode Better?\n",
    "\n",
    "Let us go over the flow of control from word trained to denoised word and loss backpropogated through our pipeline once\n",
    "\n",
    "### Pipeline Flow\n",
    "\n",
    "* **token ids for a given line are passed to form clean embeddings [seq, 768]**\n",
    "  \n",
    "* **noisy = add_noise(clean_embeddings, noise, t)** we add a noise as per a given schedule and randomly selected time step to this clean embedding\n",
    "  \n",
    "* **we denoise based off of the ddpm schedule** (we now have estimate of clean_embedding as well as a label and predicted noise)\n",
    "  \n",
    "* **logits = denoised @ text_embeddings.weight.T** this is the key, we now have a rough estimation of a seq embedding's dot product with the transpose of our text embedding weight matrix. each logit is [vocab_size] long and its argmax will give you the right predicted word at that seq id.\n",
    "\n",
    "* **reconstruction loss is going to be a crossentropy of logits and token_ids of the original sequence.** Now, when we bakcpropogate this reconstruction loss through all the layers back to the embedding matrix, the gradient change is going to nudge the weights of our embeddings to make itself more decipherable while also learning to separate these embeddings in high dimensional space based off of the semantic meaning of our sequence.\n",
    "\n",
    "---\n",
    "\n",
    "## Weight Tying vs. Separate Decoder\n",
    "\n",
    "With a separate decoder, gradients don't touch the embeddings—they're frozen. The decoder has to learn complex decision boundaries in a fixed space.\n",
    "\n",
    "With weight tying, gradients reshape the embedding space itself. The embeddings move to positions where simple dot product decoding works. After sufficient training:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efe7be6",
   "metadata": {},
   "source": [
    "```python\n",
    "def decode_weight_tied(embedding_vector):\n",
    "    logits = torch.matmul(embedding_vector, text_embeddings.weight.T)\n",
    "    return logits\n",
    "```\n",
    "- we initialise embedding layers that were discussed above to a random gaussian distribution.\n",
    "- we pass a torch tensor of a sequence of 3 and check our weight tying logic dimension wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da09eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embeddings: torch.Size([3432, 768])\n",
      "Word count embeddings: torch.Size([21, 768])\n",
      "\n",
      "SANITY CHECK: Embedding lookup\n",
      "  Input IDs: tensor([22, 57, 58], device='cuda:0')\n",
      "  Output shape: torch.Size([3, 768])\n",
      "  Expected: torch.Size([3, 768])\n",
      "\n",
      "SANITY CHECK: Weight-tied decoding\n",
      "  Input: torch.Size([3, 768])\n",
      "  Output logits: torch.Size([3, 3432])\n",
      "  Predicted IDs: tensor([22, 57, 58], device='cuda:0')\n",
      "  Original IDs: tensor([22, 57, 58], device='cuda:0')\n",
      "  Match: True\n",
      "  Expected: True (embedding→decode→embedding should be identity)\n"
     ]
    }
   ],
   "source": [
    "# Trainable text embeddings (learned during diffusion training)\n",
    "text_embeddings = nn.Embedding(vocab_size, 768, padding_idx=PAD_ID).to(device)\n",
    "# initialize embedding matrix with a random gaussian distribution\n",
    "nn.init.normal_(text_embeddings.weight, mean=0, std=0.02)\n",
    "\n",
    "# Trainable word count embeddings (0-20 words per line)\n",
    "word_count_embeddings = nn.Embedding(21, 768).to(device)\n",
    "nn.init.normal_(word_count_embeddings.weight, mean=0, std=0.02)\n",
    "\n",
    "print(f\"Text embeddings: {text_embeddings.weight.shape}\")\n",
    "print(f\"Word count embeddings: {word_count_embeddings.weight.shape}\")\n",
    "\n",
    "# SANITY CHECK: Embedding lookup test\n",
    "test_ids = torch.tensor([word2id['love'], word2id['time'], word2id['beauty']]).to(device)\n",
    "test_emb = text_embeddings(test_ids)\n",
    "\n",
    "print(f\"\\nSANITY CHECK: Embedding lookup\")\n",
    "print(f\"  Input IDs: {test_ids}\")\n",
    "print(f\"  Output shape: {test_emb.shape}\")\n",
    "print(f\"  Expected: torch.Size([3, 768])\")\n",
    "\n",
    "# SANITY CHECK: Decoder via weight tying test\n",
    "def decode_weight_tied(embedding_vector):\n",
    "    \"\"\"Decoder is just transpose of embedding matrix\"\"\"\n",
    "    logits = torch.matmul(embedding_vector, text_embeddings.weight.T)\n",
    "    return logits\n",
    "\n",
    "test_decode = decode_weight_tied(test_emb)\n",
    "print(f\"\\nSANITY CHECK: Weight-tied decoding\")\n",
    "print(f\"  Input: {test_emb.shape}\")\n",
    "print(f\"  Output logits: {test_decode.shape}\")\n",
    "print(f\"  Predicted IDs: {test_decode.argmax(dim=-1)}\")\n",
    "print(f\"  Original IDs: {test_ids}\")\n",
    "print(f\"  Match: {torch.equal(test_decode.argmax(dim=-1), test_ids)}\")\n",
    "print(f\"  Expected: True (embedding→decode→embedding should be identity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a945f3",
   "metadata": {},
   "source": [
    "### Code for upblock, downblock and textdiffusion net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86573cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From professor's document - SinusoidalPositionEmbeddings\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    \"\"\"Time step embeddings for diffusion\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "# DilatedConvBlock\n",
    "class DilatedConvBlock(nn.Module):\n",
    "    \"\"\"Dilated convolution block with POS cross-attention conditioning\"\"\"\n",
    "    def __init__(self, channels, dilation, time_emb_dim, pos_dim, num_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Dilated convolution for local text patterns\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            channels, channels,\n",
    "            kernel_size=3,\n",
    "            dilation=dilation,\n",
    "            padding=dilation\n",
    "        )\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            channels, channels,\n",
    "            kernel_size=3,\n",
    "            dilation=dilation,\n",
    "            padding=dilation\n",
    "        )\n",
    "        \n",
    "        # Time embedding projection\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_emb_dim, channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(channels, channels)\n",
    "        )\n",
    "\n",
    "        # Project POS embedding to match this layer's channel dimension\n",
    "        self.pos_proj = nn.Linear(pos_dim, channels)\n",
    "        \n",
    "        # Cross-attention to POS embeddings\n",
    "        self.pos_cross_attn = nn.MultiheadAttention(\n",
    "            channels,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Normalization layers\n",
    "        self.norm1 = nn.GroupNorm(8, channels)\n",
    "        self.norm2 = nn.GroupNorm(8, channels)\n",
    "        self.norm3 = nn.LayerNorm(channels)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Activation\n",
    "        self.act = nn.SiLU()\n",
    "        \n",
    "    def forward(self, x, time_emb, pos_embedding):\n",
    "        \"\"\"\n",
    "        x: [batch, channels, seq_len]\n",
    "        time_emb: [batch, time_emb_dim]\n",
    "        pos_embedding: [batch, 3, pos_dim] - Subject, Verb, Object embeddings\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        \n",
    "        # First conv block\n",
    "        x = self.norm1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        # Add time embedding\n",
    "        time_emb = self.time_mlp(time_emb)\n",
    "        x = x + time_emb[:, :, None]  # Broadcast across sequence\n",
    "        \n",
    "        # Second conv block\n",
    "        x = self.norm2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        # Add residual\n",
    "        x = x + residual\n",
    "\n",
    "        # Project POS to match current channel dimension\n",
    "        pos_projected = self.pos_proj(pos_embedding)  # [batch, 3, channels]\n",
    "        \n",
    "        # Cross-attention to POS (work in [batch, seq_len, channels] format)\n",
    "        x_transposed = x.transpose(1, 2)  # [batch, seq_len, channels]\n",
    "        x_transposed = self.norm3(x_transposed)\n",
    "\n",
    "        x_pos, _ = self.pos_cross_attn(\n",
    "            query=x_transposed,      # Text attends to...\n",
    "            key=pos_projected,       # POS embeddings\n",
    "            value=pos_projected\n",
    "        )\n",
    "        \n",
    "        x_transposed = x_transposed + x_pos\n",
    "        x = x_transposed.transpose(1, 2)  # Back to [batch, channels, seq_len]\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194d9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DownBlock and UpBlock initialized\n"
     ]
    }
   ],
   "source": [
    "# DownBlock\n",
    "class DownBlock(nn.Module):\n",
    "    \"\"\"Downsampling block\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dilation, time_emb_dim, pos_dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.conv_block = DilatedConvBlock(in_channels, dilation, time_emb_dim, pos_dim, num_heads)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, x, time_emb, pos_embedding):\n",
    "        x = self.conv_block(x, time_emb, pos_embedding)\n",
    "        skip = x\n",
    "        x = self.downsample(x)\n",
    "        return x, skip\n",
    "\n",
    "\n",
    "# UpBlock\n",
    "class UpBlock(nn.Module):\n",
    "    \"\"\"Upsampling block with skip connections\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dilation, time_emb_dim, pos_dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.ConvTranspose1d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        # After concatenating with skip, we have out_channels * 2\n",
    "        self.conv_block = DilatedConvBlock(out_channels * 2, dilation, time_emb_dim, pos_dim, num_heads)\n",
    "        self.out_conv = nn.Conv1d(out_channels * 2, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x, skip, time_emb, pos_embedding):\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        # Handle size mismatch between upsampled x and skip connection\n",
    "        # This can happen due to odd-sized sequences and stride=2 operations\n",
    "        if x.shape[2] != skip.shape[2]:\n",
    "            # Crop or pad to match skip connection size\n",
    "            if x.shape[2] < skip.shape[2]:\n",
    "                # Pad x to match skip\n",
    "                diff = skip.shape[2] - x.shape[2]\n",
    "                x = F.pad(x, (0, diff))\n",
    "            else:\n",
    "                # Crop x to match skip\n",
    "                x = x[:, :, :skip.shape[2]]\n",
    "        \n",
    "        # Concatenate skip connection\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv_block(x, time_emb, pos_embedding)\n",
    "        x = self.out_conv(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0f0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion model: 63,567,360 parameters\n",
      "\n",
      "SANITY CHECK: Diffusion forward pass\n",
      "  Input: torch.Size([32, 20, 768])\n",
      "  Output: torch.Size([32, 20, 768])\n",
      "  Match: True\n"
     ]
    }
   ],
   "source": [
    "# TextDiffusionUNet\n",
    "class TextDiffusionUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    1D U-Net for text diffusion with POS conditioning\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim=768,          # BERT hidden dimension\n",
    "        time_emb_dim=256,        # Time embedding dimension\n",
    "        channels=[768, 512, 256, 128],  # Channel progression through U-Net\n",
    "        dilations=[1, 2, 4, 8],  # Dilation rates for each level\n",
    "        num_heads=8,             # Number of attention heads\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert len(channels) == len(dilations), \"channels and dilations must have same length\"\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.time_emb_dim = time_emb_dim\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(time_emb_dim),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim * 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim * 4, time_emb_dim)\n",
    "        )\n",
    "        \n",
    "        # Initial projection\n",
    "        self.input_proj = nn.Conv1d(hidden_dim, channels[0], kernel_size=1)\n",
    "        \n",
    "        # Encoder (downsampling path)\n",
    "        self.down_blocks = nn.ModuleList()\n",
    "        for i in range(len(channels) - 1):\n",
    "            self.down_blocks.append(\n",
    "                DownBlock(\n",
    "                    channels[i],\n",
    "                    channels[i + 1],\n",
    "                    dilations[i],\n",
    "                    time_emb_dim,\n",
    "                    hidden_dim,  # POS dimension\n",
    "                    num_heads\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = DilatedConvBlock(\n",
    "            channels[-1],\n",
    "            dilations[-1] * 2,  # Larger dilation at bottleneck\n",
    "            time_emb_dim,\n",
    "            hidden_dim,  # POS dimension\n",
    "            num_heads,\n",
    "            dropout\n",
    "        )\n",
    "        \n",
    "        # Decoder (upsampling path)\n",
    "        self.up_blocks = nn.ModuleList()\n",
    "        for i in range(len(channels) - 1, 0, -1):\n",
    "            self.up_blocks.append(\n",
    "                UpBlock(\n",
    "                    channels[i],\n",
    "                    channels[i - 1],\n",
    "                    dilations[i - 1],\n",
    "                    time_emb_dim,\n",
    "                    hidden_dim,  # POS dimension\n",
    "                    num_heads\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Final output projection\n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.GroupNorm(8, channels[0]),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv1d(channels[0], hidden_dim, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, timesteps, pos_embedding):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, hidden_dim] - Noisy text embeddings\n",
    "            timesteps: [batch_size] - Diffusion timesteps\n",
    "            pos_embedding: [batch_size, 3, hidden_dim] - Subject, Verb, Object embeddings\n",
    "            \n",
    "        Returns:\n",
    "            [batch_size, seq_len, hidden_dim] - Predicted noise\n",
    "        \"\"\"\n",
    "        # Get time embeddings\n",
    "        time_emb = self.time_mlp(timesteps)\n",
    "        \n",
    "        # Convert to [batch, channels, seq_len] for conv operations\n",
    "        x = x.transpose(1, 2)  # [batch, hidden_dim, seq_len]\n",
    "        \n",
    "        # Initial projection\n",
    "        x = self.input_proj(x)  # [batch, channels[0], seq_len]\n",
    "        \n",
    "        # Encoder with skip connections\n",
    "        skips = []\n",
    "        for down_block in self.down_blocks:\n",
    "            x, skip = down_block(x, time_emb, pos_embedding)\n",
    "            skips.append(skip)\n",
    "        \n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x, time_emb, pos_embedding)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        for up_block in self.up_blocks:\n",
    "            skip = skips.pop()\n",
    "            x = up_block(x, skip, time_emb, pos_embedding)\n",
    "        \n",
    "        # Final projection\n",
    "        x = self.output_proj(x)\n",
    "        \n",
    "        # Convert back to [batch, seq_len, hidden_dim]\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize diffusion model\n",
    "diffusion_model = TextDiffusionUNet(\n",
    "    hidden_dim=768,\n",
    "    time_emb_dim=256,\n",
    "    channels=[768, 512, 256, 128],\n",
    "    dilations=[1, 2, 4, 8],\n",
    "    num_heads=8,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "print(f\"Diffusion model: {sum(p.numel() for p in diffusion_model.parameters()):,} parameters\")\n",
    "\n",
    "# SANITY CHECK: Forward pass\n",
    "test_batch = next(iter(dataloader))\n",
    "test_token_ids = test_batch['token_ids'].to(device)\n",
    "test_emb = text_embeddings(test_token_ids)\n",
    "test_t = torch.randint(0, 1000, (test_emb.shape[0],)).to(device)\n",
    "\n",
    "# Build dummy conditioning [batch, 4, 768] for test\n",
    "dummy_cond = torch.randn(test_emb.shape[0], 4, 768).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    noise_pred = diffusion_model(test_emb, test_t, dummy_cond)\n",
    "\n",
    "print(f\"\\nSANITY CHECK: Diffusion forward pass\")\n",
    "print(f\"  Input: {test_emb.shape}\")\n",
    "print(f\"  Output: {noise_pred.shape}\")\n",
    "print(f\"  Match: {test_emb.shape == noise_pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eca3809",
   "metadata": {},
   "source": [
    "**For the above blocks, we have only passed dummy tensors to check dimensions for inputs and outputs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a9dbef",
   "metadata": {},
   "source": [
    "- We use DDPM for training noise schedules and DDIM for inference scheduling. Using DDIM during inference will be faster as the noise levels are directly calculated across time steps. \n",
    "\n",
    "- We also do a quick sanity check on if our schedulers are adding noise proportional to timesteps selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dad05253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schedulers initialized: DDPM (training), DDIM (inference)\n",
      "\n",
      "SANITY CHECK: Noise schedule\n",
      "  Clean: torch.Size([4, 20, 768])\n",
      "  Noisy: torch.Size([4, 20, 768])\n",
      "  Timesteps tested: [100, 300, 500, 800]\n",
      "  t=100: noise magnitude=40.41\n",
      "  t=300: noise magnitude=97.09\n",
      "  t=500: noise magnitude=119.46\n",
      "  t=800: noise magnitude=123.18\n",
      "  Expected: increasing magnitudes with timestep\n",
      "  Actual: [40.405517578125, 97.09062957763672, 119.4607162475586, 123.17865753173828]\n"
     ]
    }
   ],
   "source": [
    "# Initialize noise schedulers\n",
    "train_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    "    beta_start=0.0001,\n",
    "    beta_end=0.02,\n",
    "    beta_schedule=\"linear\",\n",
    "    prediction_type=\"epsilon\"\n",
    ")\n",
    "\n",
    "inference_scheduler = DDIMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    "    beta_start=0.0001,\n",
    "    beta_end=0.02,\n",
    "    beta_schedule=\"linear\",\n",
    "    prediction_type=\"epsilon\"\n",
    ")\n",
    "\n",
    "print(f\"Schedulers initialized: DDPM (training), DDIM (inference)\")\n",
    "\n",
    "# SANITY CHECK: Noise addition test\n",
    "test_clean = test_emb[:4]  # Take 4 samples\n",
    "test_timesteps = torch.tensor([100, 300, 500, 800]).to(device)\n",
    "test_noise = torch.randn_like(test_clean)\n",
    "\n",
    "noisy = train_scheduler.add_noise(test_clean, test_noise, test_timesteps)\n",
    "\n",
    "print(f\"\\nSANITY CHECK: Noise schedule\")\n",
    "print(f\"  Clean: {test_clean.shape}\")\n",
    "print(f\"  Noisy: {noisy.shape}\")\n",
    "print(f\"  Timesteps tested: {test_timesteps.tolist()}\")\n",
    "\n",
    "# Verify noise increases with timestep\n",
    "noise_magnitudes = []\n",
    "for i, t in enumerate([100, 300, 500, 800]):\n",
    "    mag = torch.norm(noisy[i] - test_clean[i]).item()\n",
    "    noise_magnitudes.append(mag)\n",
    "    print(f\"  t={t}: noise magnitude={mag:.2f}\")\n",
    "\n",
    "print(f\"  Expected: increasing magnitudes with timestep\")\n",
    "print(f\"  Actual: {noise_magnitudes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de7e622",
   "metadata": {},
   "source": [
    "Our embeddings have the same 768 dimensions that all BERT embeddings have, so even though we dont have to use BERT we can see if initializing these embedding weights to matching tokens in our own layer can help us maybe get a kickstart as opposed to starting from full gaussian randomness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9a8648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings initialized from BERT, will be fine-tuned during training\n"
     ]
    }
   ],
   "source": [
    "# Before training, initialize our embeddings with BERT's pre-trained weights\n",
    "# Then let them fine-tune during training\n",
    "\n",
    "from transformers import BertModel\n",
    "\n",
    "bert_temp = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "bert_embeddings = bert_temp.embeddings.word_embeddings.weight.data\n",
    "\n",
    "# Map BERT vocab to our custom vocab\n",
    "with torch.no_grad():\n",
    "    for word, idx in word2id.items():\n",
    "        if word not in ['<PAD>', '<UNK>', '<START>', '<END>']:\n",
    "            # Get BERT's token ID for this word\n",
    "            bert_tokens = tokenizer.encode(word, add_special_tokens=False)\n",
    "            if len(bert_tokens) == 1:\n",
    "                bert_id = bert_tokens[0]\n",
    "                # Copy BERT's embedding\n",
    "                text_embeddings.weight[idx] = bert_embeddings[bert_id]\n",
    "\n",
    "print(\"Embeddings initialized from BERT, will be fine-tuned during training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff2641e",
   "metadata": {},
   "source": [
    "**Optimizer Configuration**\n",
    "\n",
    "For our optimizer we need to pass whatever components of the model recieves gradient updates. Here we include our diffusion model paramaters, word count embeddings and mainly the text embedding parameters.\n",
    "\n",
    "**Learning Rate Schedule**\n",
    "\n",
    "We use cosine annealing for our learning rate schedule (scaled by the number of epochs times the number of batches in our dataloader)\n",
    "\n",
    "**Collate Function**\n",
    "\n",
    "Our ```collate_fn()``` function takes from our initially generated dataset of token ids for all the required embeddings to be passed, breaks them down by id and creates individual first_word, middle_word, last_word and word_count embeddings and returns them as a conditioning stack along with the token id for a given batch. our diffusion model sees this alongside the time step at which it is predicitng noise as well as the noisy embedding for which it is predicting noise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce4a22c",
   "metadata": {},
   "source": [
    "It is important to note that we weight our overall loss from both disffusion and reconstruction tasks and use this as the metric based off of which gradient steps are taken. We can change the weight we add to our reconstruction loss at any time to see how generation quality is affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4872214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 69/69 [00:10<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Diff=0.8232 Recon=7.6508 Total=4.6486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 69/69 [00:09<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Diff=0.7276 Recon=7.5518 Total=4.5035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 69/69 [00:09<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Diff=0.6726 Recon=7.4394 Total=4.3923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 69/69 [00:09<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Diff=0.6317 Recon=7.2946 Total=4.2790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 69/69 [00:09<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Diff=0.5965 Recon=7.1991 Total=4.1960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 69/69 [00:09<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Diff=0.5682 Recon=7.1580 Total=4.1472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 69/69 [00:09<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Diff=0.5428 Recon=7.0905 Total=4.0880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 69/69 [00:10<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Diff=0.5206 Recon=7.0193 Total=4.0302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 69/69 [00:09<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Diff=0.4987 Recon=6.9260 Total=3.9617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 69/69 [00:09<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Diff=0.4804 Recon=6.9061 Total=3.9335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 69/69 [00:09<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Diff=0.4637 Recon=6.8486 Total=3.8880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 69/69 [00:09<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Diff=0.4490 Recon=6.8301 Total=3.8641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 69/69 [00:09<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Diff=0.4366 Recon=6.7241 Total=3.7986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 69/69 [00:09<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Diff=0.4213 Recon=6.6897 Total=3.7661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 69/69 [00:09<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Diff=0.4094 Recon=6.6208 Total=3.7198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 69/69 [00:09<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Diff=0.3977 Recon=6.5961 Total=3.6958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 69/69 [00:09<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Diff=0.3882 Recon=6.5744 Total=3.6754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 69/69 [00:09<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Diff=0.3787 Recon=6.5090 Total=3.6332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 69/69 [00:09<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Diff=0.3693 Recon=6.4842 Total=3.6114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 69/69 [00:09<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Diff=0.3615 Recon=6.4323 Total=3.5776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 69/69 [00:09<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Diff=0.3546 Recon=6.3623 Total=3.5357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 69/69 [00:09<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Diff=0.3468 Recon=6.3552 Total=3.5244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 69/69 [00:09<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Diff=0.3418 Recon=6.3402 Total=3.5120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 69/69 [00:09<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Diff=0.3355 Recon=6.2524 Total=3.4617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 69/69 [00:09<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Diff=0.3293 Recon=6.2274 Total=3.4430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 69/69 [00:09<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Diff=0.3248 Recon=6.1815 Total=3.4156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 69/69 [00:09<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Diff=0.3184 Recon=6.1283 Total=3.3825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 69/69 [00:09<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Diff=0.3140 Recon=6.0998 Total=3.3639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 69/69 [00:09<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Diff=0.3096 Recon=6.0927 Total=3.3559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 69/69 [00:09<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Diff=0.3050 Recon=6.0425 Total=3.3263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 69/69 [00:09<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Diff=0.2999 Recon=6.0256 Total=3.3127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 69/69 [00:09<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Diff=0.2970 Recon=5.9811 Total=3.2876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 69/69 [00:09<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Diff=0.2930 Recon=5.9438 Total=3.2649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 69/69 [00:11<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Diff=0.2889 Recon=5.9065 Total=3.2422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 69/69 [00:10<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Diff=0.2855 Recon=5.8814 Total=3.2263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 69/69 [00:10<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Diff=0.2826 Recon=5.8466 Total=3.2059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 69/69 [00:10<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Diff=0.2781 Recon=5.7776 Total=3.1669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 69/69 [00:10<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Diff=0.2756 Recon=5.7826 Total=3.1669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 69/69 [00:10<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Diff=0.2723 Recon=5.7255 Total=3.1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 69/69 [00:10<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Diff=0.2700 Recon=5.7178 Total=3.1289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 69/69 [00:10<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Diff=0.2664 Recon=5.6831 Total=3.1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 69/69 [00:10<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Diff=0.2632 Recon=5.6154 Total=3.0709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 69/69 [00:09<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Diff=0.2609 Recon=5.6267 Total=3.0743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 69/69 [00:10<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Diff=0.2587 Recon=5.5474 Total=3.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 69/69 [00:10<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Diff=0.2557 Recon=5.5419 Total=3.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 69/69 [00:10<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Diff=0.2530 Recon=5.5076 Total=3.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 69/69 [00:10<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Diff=0.2522 Recon=5.4651 Total=2.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 69/69 [00:09<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Diff=0.2486 Recon=5.4486 Total=2.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 69/69 [00:09<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Diff=0.2457 Recon=5.3853 Total=2.9383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 69/69 [00:09<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Diff=0.2450 Recon=5.3985 Total=2.9442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 69/69 [00:09<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Diff=0.2427 Recon=5.3896 Total=2.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 69/69 [00:09<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Diff=0.2406 Recon=5.3674 Total=2.9243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 69/69 [00:09<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Diff=0.2381 Recon=5.3205 Total=2.8983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 69/69 [00:09<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Diff=0.2372 Recon=5.3340 Total=2.9042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 69/69 [00:09<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Diff=0.2348 Recon=5.2695 Total=2.8695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 69/69 [00:09<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Diff=0.2336 Recon=5.2564 Total=2.8618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|██████████| 69/69 [00:09<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Diff=0.2316 Recon=5.2118 Total=2.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|██████████| 69/69 [00:09<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Diff=0.2305 Recon=5.2415 Total=2.8513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|██████████| 69/69 [00:09<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Diff=0.2286 Recon=5.1626 Total=2.8099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|██████████| 69/69 [00:09<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Diff=0.2269 Recon=5.1769 Total=2.8153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 69/69 [00:09<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Diff=0.2268 Recon=5.1478 Total=2.8007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|██████████| 69/69 [00:09<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Diff=0.2247 Recon=5.0979 Total=2.7737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|██████████| 69/69 [00:09<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Diff=0.2241 Recon=5.0930 Total=2.7706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|██████████| 69/69 [00:09<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Diff=0.2225 Recon=5.0832 Total=2.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|██████████| 69/69 [00:09<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Diff=0.2212 Recon=5.0265 Total=2.7344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|██████████| 69/69 [00:09<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Diff=0.2206 Recon=4.9993 Total=2.7202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|██████████| 69/69 [00:09<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Diff=0.2196 Recon=5.0454 Total=2.7423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|██████████| 69/69 [00:09<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Diff=0.2184 Recon=5.0538 Total=2.7452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|██████████| 69/69 [00:09<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Diff=0.2175 Recon=4.9533 Total=2.6941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|██████████| 69/69 [00:09<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Diff=0.2169 Recon=4.9748 Total=2.7043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 69/69 [00:09<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Diff=0.2162 Recon=4.9082 Total=2.6703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|██████████| 69/69 [00:09<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Diff=0.2147 Recon=4.9371 Total=2.6832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|██████████| 69/69 [00:09<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Diff=0.2148 Recon=4.9221 Total=2.6758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|██████████| 69/69 [00:09<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Diff=0.2141 Recon=4.8840 Total=2.6561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|██████████| 69/69 [00:09<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Diff=0.2138 Recon=4.8848 Total=2.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|██████████| 69/69 [00:09<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Diff=0.2124 Recon=4.8580 Total=2.6414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|██████████| 69/69 [00:09<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Diff=0.2126 Recon=4.8599 Total=2.6425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|██████████| 69/69 [00:09<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Diff=0.2117 Recon=4.8855 Total=2.6545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|██████████| 69/69 [00:09<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: Diff=0.2125 Recon=4.8434 Total=2.6343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|██████████| 69/69 [00:09<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Diff=0.2116 Recon=4.8771 Total=2.6501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 69/69 [00:09<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Diff=0.2108 Recon=4.8488 Total=2.6352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|██████████| 69/69 [00:09<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: Diff=0.2095 Recon=4.7801 Total=2.5995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100: 100%|██████████| 69/69 [00:09<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: Diff=0.2098 Recon=4.7714 Total=2.5955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100: 100%|██████████| 69/69 [00:09<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: Diff=0.2097 Recon=4.8269 Total=2.6232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: 100%|██████████| 69/69 [00:09<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Diff=0.2084 Recon=4.7808 Total=2.5988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100: 100%|██████████| 69/69 [00:09<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: Diff=0.2093 Recon=4.8392 Total=2.6290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100: 100%|██████████| 69/69 [00:09<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Diff=0.2099 Recon=4.8002 Total=2.6100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100: 100%|██████████| 69/69 [00:09<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Diff=0.2088 Recon=4.7960 Total=2.6068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100: 100%|██████████| 69/69 [00:09<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Diff=0.2087 Recon=4.8138 Total=2.6156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100: 100%|██████████| 69/69 [00:09<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Diff=0.2091 Recon=4.7686 Total=2.5934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 69/69 [00:09<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Diff=0.2082 Recon=4.7577 Total=2.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: 100%|██████████| 69/69 [00:09<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Diff=0.2080 Recon=4.7790 Total=2.5975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100: 100%|██████████| 69/69 [00:09<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Diff=0.2087 Recon=4.7457 Total=2.5815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100: 100%|██████████| 69/69 [00:09<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Diff=0.2078 Recon=4.7769 Total=2.5962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100: 100%|██████████| 69/69 [00:09<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: Diff=0.2077 Recon=4.7093 Total=2.5623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100: 100%|██████████| 69/69 [00:09<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: Diff=0.2076 Recon=4.7179 Total=2.5666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: 100%|██████████| 69/69 [00:09<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Diff=0.2075 Recon=4.7300 Total=2.5726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100: 100%|██████████| 69/69 [00:09<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: Diff=0.2072 Recon=4.7608 Total=2.5875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100: 100%|██████████| 69/69 [00:09<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Diff=0.2073 Recon=4.7664 Total=2.5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 69/69 [00:09<00:00,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Diff=0.2073 Recon=4.7549 Total=2.5847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimizer: train embeddings + diffusion + word_count_embeddings jointly\n",
    "optimizer = optim.AdamW(\n",
    "    list(text_embeddings.parameters()) + \n",
    "    list(word_count_embeddings.parameters()) + \n",
    "    list(diffusion_model.parameters()),\n",
    "    lr=1e-4,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=100 * len(dataloader),\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Collate function to build conditioning\n",
    "def collate_fn(batch):\n",
    "    token_ids = torch.stack([item['token_ids'] for item in batch])\n",
    "    \n",
    "    conditioning_batch = []\n",
    "    for item in batch:\n",
    "        # Word count embedding (learnable)\n",
    "        wc_emb = word_count_embeddings(torch.tensor(item['word_count']).to(device))\n",
    "        \n",
    "        # Position word embeddings (from trainable text_embeddings)\n",
    "        first_emb = text_embeddings(torch.tensor(item['first_id']).to(device))\n",
    "        middle_emb = text_embeddings(torch.tensor(item['middle_id']).to(device))\n",
    "        last_emb = text_embeddings(torch.tensor(item['last_id']).to(device))\n",
    "        \n",
    "        # Stack to [4, 768]\n",
    "        conditioning = torch.stack([wc_emb, first_emb, middle_emb, last_emb])\n",
    "        conditioning_batch.append(conditioning)\n",
    "    \n",
    "    return {\n",
    "        'token_ids': token_ids,\n",
    "        'conditioning': torch.stack(conditioning_batch)\n",
    "    }\n",
    "\n",
    "# Recreate dataloader with collate function\n",
    "dataloader = DataLoader(shakespeare_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "history = {'epoch': [], 'diffusion_loss': [], 'reconstruction_loss': [], 'total_loss': []}\n",
    "\n",
    "diffusion_model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_diff = 0\n",
    "    epoch_recon = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        token_ids = batch['token_ids'].to(device)\n",
    "        conditioning = batch['conditioning'].to(device)\n",
    "        \n",
    "        # Get embeddings from trainable layer\n",
    "        clean_embeddings = text_embeddings(token_ids)\n",
    "        \n",
    "        # Sample timesteps and add noise\n",
    "        timesteps = torch.randint(0, 1000, (clean_embeddings.shape[0],)).to(device)\n",
    "        noise = torch.randn_like(clean_embeddings)\n",
    "        noisy_embeddings = train_scheduler.add_noise(clean_embeddings, noise, timesteps)\n",
    "        \n",
    "        # Predict noise\n",
    "        predicted_noise = diffusion_model(noisy_embeddings, timesteps, conditioning)\n",
    "        diffusion_loss = F.mse_loss(predicted_noise, noise)\n",
    "        \n",
    "        # Denoise\n",
    "        alpha_prod = train_scheduler.alphas_cumprod[timesteps].view(-1, 1, 1)\n",
    "        denoised = (noisy_embeddings - torch.sqrt(1 - alpha_prod) * predicted_noise) / torch.sqrt(alpha_prod)\n",
    "        denoised = torch.clamp(denoised, -3, 3)\n",
    "        \n",
    "        # Decode via weight tying (embeddings.weight @ denoised)\n",
    "        logits = torch.matmul(denoised, text_embeddings.weight.T)\n",
    "        \n",
    "        reconstruction_loss = F.cross_entropy(\n",
    "            logits.reshape(-1, vocab_size),\n",
    "            token_ids.reshape(-1),\n",
    "            ignore_index=PAD_ID\n",
    "        )\n",
    "        \n",
    "        # Combined loss (embeddings get gradients from both losses)\n",
    "        total_loss = diffusion_loss + 0.01 * reconstruction_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            list(text_embeddings.parameters()) + \n",
    "            list(word_count_embeddings.parameters()) + \n",
    "            list(diffusion_model.parameters()),\n",
    "            max_norm=1.0\n",
    "        )\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_diff += diffusion_loss.item()\n",
    "        epoch_recon += reconstruction_loss.item()\n",
    "    \n",
    "    avg_diff = epoch_diff / len(dataloader)\n",
    "    avg_recon = epoch_recon / len(dataloader)\n",
    "    avg_total = avg_diff + 0.5 * avg_recon\n",
    "    \n",
    "    history['epoch'].append(epoch + 1)\n",
    "    history['diffusion_loss'].append(avg_diff)\n",
    "    history['reconstruction_loss'].append(avg_recon)\n",
    "    history['total_loss'].append(avg_total)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Diff={avg_diff:.4f} Recon={avg_recon:.4f} Total={avg_total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4defd77",
   "metadata": {},
   "source": [
    "We use a simple line generator function that removes any conditional tokens and based off of the parameters we have trained our diffusion model on, generates a line for a given length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e0a3cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated samples:\n",
      "======================================================================\n",
      "\n",
      "Condition: [from, desire, increase] count=6\n",
      "Generated: pleasures vile truths exchequer whereupon conscience thou whereupon deserves likeness denote lend reigned temperate incapable pry honoring whereupon vantage parallels\n",
      "\n",
      "Condition: [that, rose, die] count=8\n",
      "Generated: pry ripe slain whereupon for thereof repay thou rents , commits reigned reigned locked flown owes whereupon pry proceeds accusing\n",
      "\n",
      "Condition: [thy, love, heart] count=7\n",
      "Generated: declines , richer whereupon rents deserts whereupon whereupon whereupon afar reigned exchequer possessing remedy sinks twain astonished proves treason exceeds\n",
      "\n",
      "Condition: [when, time, beauty] count=8\n",
      "Generated: disperse clears orphans commits declines richer . defects breeds anchored lawful exceed esteem whereupon commits unrest exceeds flourish chopped whoever\n"
     ]
    }
   ],
   "source": [
    "def generate_line(first_word, middle_word, last_word, word_count=8, num_steps=100):\n",
    "    \"\"\"\n",
    "    Generate Shakespeare line with positional conditioning.\n",
    "    \n",
    "    Args:\n",
    "        first_word: word at start of line\n",
    "        middle_word: word in middle\n",
    "        last_word: word at end\n",
    "        word_count: target line length\n",
    "        num_steps: DDIM denoising steps\n",
    "    \n",
    "    Returns:\n",
    "        Generated text string\n",
    "    \"\"\"\n",
    "    diffusion_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Build conditioning [4, 768]\n",
    "        wc_emb = word_count_embeddings(torch.tensor(word_count).to(device))\n",
    "        \n",
    "        first_id = word2id.get(first_word, UNK_ID)\n",
    "        middle_id = word2id.get(middle_word, UNK_ID)\n",
    "        last_id = word2id.get(last_word, UNK_ID)\n",
    "        \n",
    "        first_emb = text_embeddings(torch.tensor(first_id).to(device))\n",
    "        middle_emb = text_embeddings(torch.tensor(middle_id).to(device))\n",
    "        last_emb = text_embeddings(torch.tensor(last_id).to(device))\n",
    "        \n",
    "        conditioning = torch.stack([wc_emb, first_emb, middle_emb, last_emb]).unsqueeze(0)\n",
    "        \n",
    "        # Start from noise\n",
    "        latent = torch.randn(1, 20, 768).to(device)\n",
    "        \n",
    "        # DDIM denoising\n",
    "        inference_scheduler.set_timesteps(num_steps)\n",
    "        \n",
    "        for t in inference_scheduler.timesteps:\n",
    "            noise_pred = diffusion_model(latent, torch.tensor([t]).to(device), conditioning)\n",
    "            latent = inference_scheduler.step(noise_pred, t, latent).prev_sample\n",
    "        \n",
    "        # Decode via weight tying\n",
    "        logits = torch.matmul(latent, text_embeddings.weight.T)\n",
    "        token_ids = logits.argmax(dim=-1)[0]\n",
    "        \n",
    "        # Convert IDs to words\n",
    "        words = [id2word.get(idx.item(), '<UNK>') for idx in token_ids]\n",
    "        \n",
    "        # Remove padding and special tokens\n",
    "        text = ' '.join([w for w in words if w not in ['<PAD>', '<UNK>', '<START>', '<END>']])\n",
    "        \n",
    "        return text\n",
    "\n",
    "# Test generation\n",
    "test_cases = [\n",
    "    ('from', 'desire', 'increase', 6),\n",
    "    ('that', 'rose', 'die', 8),\n",
    "    ('thy', 'love', 'heart', 7),\n",
    "    ('when', 'time', 'beauty', 8),\n",
    "]\n",
    "\n",
    "print(\"Generated samples:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for first, middle, last, count in test_cases:\n",
    "    generated = generate_line(first, middle, last, count, num_steps=100)\n",
    "    print(f\"\\nCondition: [{first}, {middle}, {last}] count={count}\")\n",
    "    print(f\"Generated: {generated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cbad9c",
   "metadata": {},
   "source": [
    "AS word salad but theres enough diversity and the main challenge we have overcome is the decoding aspect our weight tying strategy is working pretty well consider our reconstruction loss was still high. However our word count embedding is not being listened to at all and the structure of the sentences are pretty random.\n",
    "\n",
    "Now that we have figured that our approach works for decoding, let us try another way of passing POS tokens for our shakespeare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf90dca4",
   "metadata": {},
   "source": [
    "## ATTEMPT 2: NGRAMS\n",
    "\n",
    "- Our diffusion model needs a lot more data than what we have. The primary reason for why we use n-gram strategy is becasue it gives much more data.\n",
    "\n",
    "- On top of this, our model also needs to learn sentence structure. \n",
    "\n",
    "So let us try to adopt this strategy and use that to generate more data for our diffusion model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec5431",
   "metadata": {},
   "source": [
    "- the model needs to differentiate between ngrams that are only portiosn of a line from ngrams representative of the entire line.\n",
    "- so our conditioning stack is going to include length of the words in the ngram, position of the n gram within that sentence, first word in the n gram, last word of the n gram\n",
    "- position can be: START/MIDDLE/END/COMPLETE so in a way we are helping the model stress on the fact that on top of the whole line to be diffused these are the appterns within which you need to denoise inside of each line.\n",
    "\n",
    "\n",
    "We have a utility function where based on min and max length of n-grams required, we process the lines, break it down by that many possible n grams and inside a loop try to check with the id of the line and the generated n gram if we fall under the start of the sentence, end of the sentence or the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd800058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating n-grams: 100%|██████████| 2185/2185 [00:00<00:00, 10920.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N-gram dataset created: 60426 samples\n",
      "\n",
      "Length distribution:\n",
      "  2 words: 14985 ( 24.8%)\n",
      "  3 words: 12802 ( 21.2%)\n",
      "  4 words: 10619 ( 17.6%)\n",
      "  5 words:  8436 ( 14.0%)\n",
      "  6 words:  6254 ( 10.3%)\n",
      "  7 words:  4120 (  6.8%)\n",
      "  8 words:  2230 (  3.7%)\n",
      "  9 words:   822 (  1.4%)\n",
      "  10 words:   157 (  0.3%)\n",
      "  11 words:     1 (  0.0%)\n",
      "\n",
      "Position distribution:\n",
      "  START     : 12802 ( 21.2%)\n",
      "  MIDDLE    : 32639 ( 54.0%)\n",
      "  END       : 12802 ( 21.2%)\n",
      "  COMPLETE  :  2183 (  3.6%)\n",
      "\n",
      "Sample n-grams:\n",
      "0: from fairest creatures we desire increase... | len=6 pos=COMPLETE\n",
      "1000: thou art thy mother's glass and she in... | len=9 pos=COMPLETE\n",
      "10000: till then not... | len=3 pos=START\n",
      "20000: can bring him to his sweet up-locked treasure... | len=8 pos=COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_ngram_dataset(lines, word2id, min_n=2, max_n=10):\n",
    "    \"\"\"\n",
    "    Create n-gram dataset with structural position markers.\n",
    "    \n",
    "    Each n-gram includes:\n",
    "    - text: the n-gram words\n",
    "    - length: number of words\n",
    "    - position: START/MIDDLE/END/COMPLETE\n",
    "    - first_word: first word in n-gram\n",
    "    - last_word: last word in n-gram\n",
    "    \n",
    "    Returns list of n-gram samples with conditioning info\n",
    "    \"\"\"\n",
    "    POSITIONS = ['START', 'MIDDLE', 'END', 'COMPLETE']\n",
    "    dataset = []\n",
    "    \n",
    "    for line in tqdm(lines, desc=\"Creating n-grams\"):\n",
    "        # Tokenize line\n",
    "        words = line.lower().replace(',', ' ,').replace('.', ' .').replace('!', ' !').replace('?', ' ?').split()\n",
    "        words = [w.strip('.,!?;:\\'\"') for w in words if len(w.strip('.,!?;:\\'\"')) > 1]\n",
    "        \n",
    "        if len(words) < 2:\n",
    "            continue\n",
    "        \n",
    "        line_len = len(words)\n",
    "        \n",
    "        # Add complete line\n",
    "        dataset.append({\n",
    "            'words': words,\n",
    "            'length': line_len,\n",
    "            'position': 'COMPLETE',\n",
    "            'first_word': words[0],\n",
    "            'last_word': words[-1]\n",
    "        })\n",
    "        \n",
    "        # Extract n-grams\n",
    "        for n in range(min_n, min(max_n + 1, line_len + 1)):\n",
    "            for i in range(line_len - n + 1):\n",
    "                ngram_words = words[i:i+n]\n",
    "                \n",
    "                # Determine position in original line\n",
    "                if i == 0 and i + n == line_len:\n",
    "                    continue  # Already added as COMPLETE\n",
    "                elif i == 0:\n",
    "                    position = 'START'\n",
    "                elif i + n == line_len:\n",
    "                    position = 'END'\n",
    "                else:\n",
    "                    position = 'MIDDLE'\n",
    "                \n",
    "                dataset.append({\n",
    "                    'words': ngram_words,\n",
    "                    'length': n,\n",
    "                    'position': position,\n",
    "                    'first_word': ngram_words[0],\n",
    "                    'last_word': ngram_words[-1]\n",
    "                })\n",
    "    \n",
    "    return dataset, POSITIONS\n",
    "\n",
    "# Generate n-gram dataset\n",
    "ngram_data, POSITIONS = create_ngram_dataset(lines, word2id, min_n=2, max_n=10)\n",
    "\n",
    "print(f\"\\nN-gram dataset created: {len(ngram_data)} samples\")\n",
    "\n",
    "# Statistics\n",
    "from collections import Counter\n",
    "lengths = Counter([d['length'] for d in ngram_data])\n",
    "positions = Counter([d['position'] for d in ngram_data])\n",
    "\n",
    "print(f\"\\nLength distribution:\")\n",
    "for length in sorted(lengths.keys())[:10]:\n",
    "    print(f\"  {length} words: {lengths[length]:5d} ({100*lengths[length]/len(ngram_data):5.1f}%)\")\n",
    "\n",
    "print(f\"\\nPosition distribution:\")\n",
    "for pos in POSITIONS:\n",
    "    print(f\"  {pos:10s}: {positions[pos]:5d} ({100*positions[pos]/len(ngram_data):5.1f}%)\")\n",
    "\n",
    "# Sample verification\n",
    "print(f\"\\nSample n-grams:\")\n",
    "for i in [0, 1000, 10000, 20000]:\n",
    "    if i < len(ngram_data):\n",
    "        d = ngram_data[i]\n",
    "        print(f\"{i}: {' '.join(d['words'][:8])}... | len={d['length']} pos={d['position']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "556290b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 'from fairest', 3: 'from fairest creatures', 4: 'from fairest creatures we', 5: 'from fairest creatures we desire', 6: 'from fairest creatures we desire increase', 7: \"that thereby beauty's rose might never die\", 8: 'but as the riper should by time decease', 9: 'thyself thy foe to thy sweet self too cruel', 10: \"to eat the world's due by the grave and thee\", 11: 'till then not show my head where thou mayst prove me'}\n"
     ]
    }
   ],
   "source": [
    "print({n: ' '.join(next(d['words'] for d in ngram_data if d['length']==n)) for n in sorted({d['length'] for d in ngram_data})})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b90270",
   "metadata": {},
   "source": [
    "The below class and collate functions do exactly what we did with the previous dataset except this time the conditioning embedding includes length of ngram, position of the ngram within the sentence, start word and end word of the ngram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32512cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating n-gram dataset: 60426 samples\n",
      "Dataset ready: 60426 samples\n",
      "Position embeddings: torch.Size([4, 768])\n",
      "Length embeddings: torch.Size([12, 768])\n",
      "N-gram dataloader: 1889 batches\n",
      "Ready to train on 60426 samples\n"
     ]
    }
   ],
   "source": [
    "class NgramDataset(Dataset):\n",
    "    \"\"\"\n",
    "    N-gram dataset with length and position conditioning.\n",
    "    \n",
    "    Conditioning: [length_emb, position_emb, first_word_emb, last_word_emb]\n",
    "    \"\"\"\n",
    "    def __init__(self, ngram_data, word2id, max_length=20):\n",
    "        self.data = ngram_data\n",
    "        self.word2id = word2id\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Position to ID mapping\n",
    "        self.POSITIONS = ['START', 'MIDDLE', 'END', 'COMPLETE']\n",
    "        self.pos2id = {pos: i for i, pos in enumerate(self.POSITIONS)}\n",
    "        \n",
    "        print(f\"Creating n-gram dataset: {len(ngram_data)} samples\")\n",
    "        \n",
    "        self.token_ids = []\n",
    "        self.lengths = []\n",
    "        self.positions = []\n",
    "        self.first_ids = []\n",
    "        self.last_ids = []\n",
    "        \n",
    "        for item in ngram_data:\n",
    "            # Convert words to token IDs\n",
    "            ids = [word2id.get(word, UNK_ID) for word in item['words']]\n",
    "            \n",
    "            # Pad to max_length\n",
    "            if len(ids) < max_length:\n",
    "                ids = ids + [PAD_ID] * (max_length - len(ids))\n",
    "            else:\n",
    "                ids = ids[:max_length]\n",
    "            \n",
    "            self.token_ids.append(torch.tensor(ids, dtype=torch.long))\n",
    "            self.lengths.append(item['length'])\n",
    "            self.positions.append(self.pos2id[item['position']])\n",
    "            self.first_ids.append(word2id.get(item['first_word'], UNK_ID))\n",
    "            self.last_ids.append(word2id.get(item['last_word'], UNK_ID))\n",
    "        \n",
    "        print(f\"Dataset ready: {len(self.token_ids)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.token_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'token_ids': self.token_ids[idx],\n",
    "            'length': self.lengths[idx],\n",
    "            'position': self.positions[idx],\n",
    "            'first_id': self.first_ids[idx],\n",
    "            'last_id': self.last_ids[idx]\n",
    "        }\n",
    "\n",
    "# Create n-gram dataset\n",
    "ngram_dataset = NgramDataset(ngram_data, word2id, max_length=20)\n",
    "\n",
    "# Create position embeddings (4 positions)\n",
    "position_embeddings = nn.Embedding(4, 768).to(device)\n",
    "nn.init.normal_(position_embeddings.weight, mean=0, std=0.02)\n",
    "\n",
    "# Create length embeddings (2-11 words)\n",
    "length_embeddings = nn.Embedding(12, 768).to(device)\n",
    "nn.init.normal_(length_embeddings.weight, mean=0, std=0.02)\n",
    "\n",
    "print(f\"Position embeddings: {position_embeddings.weight.shape}\")\n",
    "print(f\"Length embeddings: {length_embeddings.weight.shape}\")\n",
    "\n",
    "# Collate function for n-grams\n",
    "def collate_ngram(batch):\n",
    "    token_ids = torch.stack([item['token_ids'] for item in batch])\n",
    "    \n",
    "    conditioning_batch = []\n",
    "    for item in batch:\n",
    "        len_emb = length_embeddings(torch.tensor(item['length']).to(device))\n",
    "        pos_emb = position_embeddings(torch.tensor(item['position']).to(device))\n",
    "        first_emb = text_embeddings(torch.tensor(item['first_id']).to(device))\n",
    "        last_emb = text_embeddings(torch.tensor(item['last_id']).to(device))\n",
    "        \n",
    "        conditioning = torch.stack([len_emb, pos_emb, first_emb, last_emb])\n",
    "        conditioning_batch.append(conditioning)\n",
    "    \n",
    "    return {\n",
    "        'token_ids': token_ids,\n",
    "        'conditioning': torch.stack(conditioning_batch)\n",
    "    }\n",
    "\n",
    "# Create dataloader\n",
    "ngram_loader = DataLoader(ngram_dataset, batch_size=32, shuffle=True, collate_fn=collate_ngram)\n",
    "\n",
    "print(f\"N-gram dataloader: {len(ngram_loader)} batches\")\n",
    "print(f\"Ready to train on {len(ngram_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ce093",
   "metadata": {},
   "source": [
    "The same model is initialized except now we have increased the last two channels from 128 to 256 and 256 to 384. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe491b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models reinitialized for n-gram training\n",
      "  Text embeddings: torch.Size([3432, 768])\n",
      "  Diffusion params: 70,358,528\n"
     ]
    }
   ],
   "source": [
    "# Reinitialize text embeddings \n",
    "text_embeddings = nn.Embedding(vocab_size, 768, padding_idx=PAD_ID).to(device)\n",
    "nn.init.normal_(text_embeddings.weight, mean=0, std=0.02)\n",
    "\n",
    "# Reinitialize diffusion model \n",
    "diffusion_model = TextDiffusionUNet(\n",
    "    hidden_dim=768,\n",
    "    time_emb_dim=256,\n",
    "    channels=[768, 512, 384, 256],\n",
    "    dilations=[1, 2, 4, 8],\n",
    "    num_heads=8,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "print(f\"Models reinitialized for n-gram training\")\n",
    "print(f\"  Text embeddings: {text_embeddings.weight.shape}\")\n",
    "print(f\"  Diffusion params: {sum(p.numel() for p in diffusion_model.parameters()):,}\")\n",
    "\n",
    "# New optimizer for all trainable components\n",
    "optimizer = optim.AdamW(\n",
    "    list(text_embeddings.parameters()) + \n",
    "    list(length_embeddings.parameters()) + \n",
    "    list(position_embeddings.parameters()) + \n",
    "    list(diffusion_model.parameters()),\n",
    "    lr=1e-4,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=100 * len(ngram_loader),\n",
    "    eta_min=1e-6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8051ceca",
   "metadata": {},
   "source": [
    "the alpha parameter determines the weight forced on the reconstruction loss. let us keep it at 0.3 and train on the same training loop used as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5807b284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 1889/1889 [04:26<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Diff=1.0340 Recon=6.5488 Total=2.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 1889/1889 [04:28<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Diff=0.9167 Recon=5.4857 Total=2.5624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 1889/1889 [04:30<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Diff=0.8544 Recon=4.7745 Total=2.2868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 1889/1889 [04:31<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Diff=0.8138 Recon=4.2590 Total=2.0915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 1889/1889 [04:29<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Diff=0.7792 Recon=3.8864 Total=1.9451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 1889/1889 [04:30<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Diff=0.7495 Recon=3.6234 Total=1.8365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 1889/1889 [04:29<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Diff=0.7229 Recon=3.4348 Total=1.7533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 1889/1889 [04:30<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Diff=0.7004 Recon=3.2889 Total=1.6870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 1889/1889 [04:31<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Diff=0.6795 Recon=3.1788 Total=1.6331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 1889/1889 [04:30<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Diff=0.6634 Recon=3.0815 Total=1.5879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 1889/1889 [04:32<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Diff=0.6483 Recon=2.9970 Total=1.5474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 1889/1889 [04:29<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Diff=0.6363 Recon=2.9223 Total=1.5129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 1889/1889 [04:28<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Diff=0.6231 Recon=2.8574 Total=1.4803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 1889/1889 [04:30<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Diff=0.6142 Recon=2.7765 Total=1.4472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 1889/1889 [04:29<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Diff=0.6058 Recon=2.7207 Total=1.4220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 1889/1889 [04:28<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Diff=0.5984 Recon=2.6658 Total=1.3982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 1889/1889 [04:28<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Diff=0.5886 Recon=2.6197 Total=1.3745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 1889/1889 [04:28<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Diff=0.5810 Recon=2.5644 Total=1.3503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 1889/1889 [04:28<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Diff=0.5742 Recon=2.5097 Total=1.3271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 1889/1889 [04:28<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Diff=0.5672 Recon=2.4648 Total=1.3067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 1889/1889 [04:28<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Diff=0.5623 Recon=2.4245 Total=1.2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 1889/1889 [04:30<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Diff=0.5559 Recon=2.3827 Total=1.2707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 1889/1889 [04:31<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Diff=0.5501 Recon=2.3415 Total=1.2525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 1889/1889 [04:28<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Diff=0.5445 Recon=2.3111 Total=1.2379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 1889/1889 [04:32<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Diff=0.5388 Recon=2.2642 Total=1.2181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 1889/1889 [04:33<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Diff=0.5343 Recon=2.2437 Total=1.2074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 1889/1889 [04:24<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Diff=0.5294 Recon=2.2108 Total=1.1926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 1889/1889 [04:27<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Diff=0.5241 Recon=2.1750 Total=1.1766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 1889/1889 [04:34<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Diff=0.5192 Recon=2.1436 Total=1.1623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 1889/1889 [04:35<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Diff=0.5158 Recon=2.1172 Total=1.1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 1889/1889 [04:33<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Diff=0.5114 Recon=2.0906 Total=1.1386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Diff=0.5065 Recon=2.0569 Total=1.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 1889/1889 [04:28<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Diff=0.5025 Recon=2.0288 Total=1.1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 1889/1889 [04:28<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Diff=0.4973 Recon=2.0035 Total=1.0984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 1889/1889 [04:37<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Diff=0.4932 Recon=1.9771 Total=1.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 1889/1889 [04:38<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Diff=0.4908 Recon=1.9559 Total=1.0775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 1889/1889 [04:38<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Diff=0.4856 Recon=1.9232 Total=1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 1889/1889 [04:38<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Diff=0.4823 Recon=1.8990 Total=1.0520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 1889/1889 [04:21<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Diff=0.4786 Recon=1.8755 Total=1.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 1889/1889 [04:19<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Diff=0.4759 Recon=1.8633 Total=1.0348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 1889/1889 [04:18<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Diff=0.4716 Recon=1.8223 Total=1.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 1889/1889 [04:18<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Diff=0.4686 Recon=1.8083 Total=1.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Diff=0.4645 Recon=1.7936 Total=1.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Diff=0.4609 Recon=1.7552 Total=0.9874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 1889/1889 [04:24<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Diff=0.4576 Recon=1.7444 Total=0.9810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Diff=0.4543 Recon=1.7249 Total=0.9718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Diff=0.4501 Recon=1.6943 Total=0.9584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 1889/1889 [04:24<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Diff=0.4469 Recon=1.6718 Total=0.9485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 1889/1889 [04:29<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Diff=0.4445 Recon=1.6503 Total=0.9396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 1889/1889 [04:33<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Diff=0.4409 Recon=1.6319 Total=0.9304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100:   2%|▏         | 45/1889 [00:06<04:37,  6.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     62\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 64\u001b[0m     epoch_diff \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     epoch_recon \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reconstruction_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     67\u001b[0m avg_diff \u001b[38;5;241m=\u001b[39m epoch_diff \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(ngram_loader)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "num_epochs = 100\n",
    "alpha = 0.3  # Reconstruction loss weight\n",
    "\n",
    "# Training history\n",
    "ngram_history = {\n",
    "    'epoch': [],\n",
    "    'diffusion_loss': [],\n",
    "    'reconstruction_loss': [],\n",
    "    'total_loss': []\n",
    "}\n",
    "\n",
    "diffusion_model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_diff = 0\n",
    "    epoch_recon = 0\n",
    "    \n",
    "    for batch in tqdm(ngram_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        token_ids = batch['token_ids'].to(device)\n",
    "        conditioning = batch['conditioning'].to(device)\n",
    "        \n",
    "        # Get trainable embeddings\n",
    "        clean_embeddings = text_embeddings(token_ids)\n",
    "        \n",
    "        # Add noise at random timesteps\n",
    "        timesteps = torch.randint(0, 1000, (clean_embeddings.shape[0],)).to(device)\n",
    "        noise = torch.randn_like(clean_embeddings)\n",
    "        noisy_embeddings = train_scheduler.add_noise(clean_embeddings, noise, timesteps)\n",
    "        \n",
    "        # Predict noise\n",
    "        predicted_noise = diffusion_model(noisy_embeddings, timesteps, conditioning)\n",
    "        diffusion_loss = F.mse_loss(predicted_noise, noise)\n",
    "        \n",
    "        # Denoise\n",
    "        alpha_prod = train_scheduler.alphas_cumprod[timesteps].view(-1, 1, 1)\n",
    "        denoised = (noisy_embeddings - torch.sqrt(1 - alpha_prod) * predicted_noise) / torch.sqrt(alpha_prod)\n",
    "        denoised = torch.clamp(denoised, -3, 3)\n",
    "        \n",
    "        # Weight-tied decoding\n",
    "        logits = torch.matmul(denoised, text_embeddings.weight.T)\n",
    "        \n",
    "        reconstruction_loss = F.cross_entropy(\n",
    "            logits.reshape(-1, vocab_size),\n",
    "            token_ids.reshape(-1),\n",
    "            ignore_index=PAD_ID\n",
    "        )\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = diffusion_loss + alpha * reconstruction_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            list(text_embeddings.parameters()) + \n",
    "            list(length_embeddings.parameters()) + \n",
    "            list(position_embeddings.parameters()) + \n",
    "            list(diffusion_model.parameters()),\n",
    "            max_norm=1.0\n",
    "        )\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_diff += diffusion_loss.item()\n",
    "        epoch_recon += reconstruction_loss.item()\n",
    "    \n",
    "    avg_diff = epoch_diff / len(ngram_loader)\n",
    "    avg_recon = epoch_recon / len(ngram_loader)\n",
    "    avg_total = avg_diff + alpha * avg_recon\n",
    "    \n",
    "    ngram_history['epoch'].append(epoch + 1)\n",
    "    ngram_history['diffusion_loss'].append(avg_diff)\n",
    "    ngram_history['reconstruction_loss'].append(avg_recon)\n",
    "    ngram_history['total_loss'].append(avg_total)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Diff={avg_diff:.4f} Recon={avg_recon:.4f} Total={avg_total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352a9d46",
   "metadata": {},
   "source": [
    "let us save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd68667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved: ngram_model_epoch50.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save({\n",
    "    'text_embeddings': text_embeddings.state_dict(),\n",
    "    'length_embeddings': length_embeddings.state_dict(),\n",
    "    'position_embeddings': position_embeddings.state_dict(),\n",
    "    'diffusion_model': diffusion_model.state_dict(),\n",
    "    'vocab': {'word2id': word2id, 'id2word': id2word},\n",
    "    'history': ngram_history\n",
    "}, 'ngram_model_epoch50.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4fa813",
   "metadata": {},
   "source": [
    "**Plotting all the different losses to see if we can still train before plateauing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cbb678b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(ngram_history['epoch'], ngram_history['diffusion_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Diffusion Loss')\n",
    "plt.title('Diffusion Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(ngram_history['epoch'], ngram_history['reconstruction_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Reconstruction Loss')\n",
    "plt.title('Reconstruction Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(ngram_history['epoch'], ngram_history['total_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.title('Total Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c8c93",
   "metadata": {},
   "source": [
    "I think we can still train further since the losses are continously reducing at a constant rate still. Let us take this moment to test our generation.\n",
    "\n",
    "let us generate some sample lines to check our generation quality. We use the conditioning tokens to guide our diffusion model to denoise some lines as shown below. The number of denosiing steps can also be a useful parameter to see at what range our model is comfortable at denoising from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac9f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngram(first_word, last_word, length=8, position='COMPLETE', num_steps=100):\n",
    "    \"\"\"Generate n-gram with structural conditioning\"\"\"\n",
    "    diffusion_model.eval()\n",
    "\n",
    "    # Map position labels → integer IDs for embedding lookup\n",
    "    POS_MAP = {'START': 0, 'MIDDLE': 1, 'END': 2, 'COMPLETE': 3}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Build 4-part conditioning vector\n",
    "        len_emb = length_embeddings(torch.tensor(length).to(device))                  # target length\n",
    "        pos_emb = position_embeddings(torch.tensor(POS_MAP[position]).to(device))    # structural position type\n",
    "        first_emb = text_embeddings(torch.tensor(word2id.get(first_word, UNK_ID)).to(device))  # first-word embedding\n",
    "        last_emb  = text_embeddings(torch.tensor(word2id.get(last_word,  UNK_ID)).to(device))  # last-word embedding\n",
    "\n",
    "        # Stack into shape [1, 4, 768] for the model\n",
    "        conditioning = torch.stack([len_emb, pos_emb, first_emb, last_emb]).unsqueeze(0)\n",
    "\n",
    "        # Start diffusion from pure noise\n",
    "        latent = torch.randn(1, 20, 768).to(device)\n",
    "\n",
    "        # Setup DDIM inference steps\n",
    "        inference_scheduler.set_timesteps(num_steps)\n",
    "\n",
    "        # Denoising loop\n",
    "        for t in inference_scheduler.timesteps:\n",
    "            noise_pred = diffusion_model(latent, torch.tensor([t]).to(device), conditioning)\n",
    "            latent = inference_scheduler.step(noise_pred, t, latent).prev_sample\n",
    "\n",
    "        # Decode: project latent → vocabulary logits using weight tying\n",
    "        logits = torch.matmul(latent, text_embeddings.weight.T)\n",
    "        token_ids = logits.argmax(dim=-1)[0]\n",
    "\n",
    "        # Convert IDs → words and strip padding/specials\n",
    "        words = [\n",
    "            id2word[idx.item()]\n",
    "            for idx in token_ids\n",
    "            if idx.item() in id2word and id2word[idx.item()] != '<PAD>'\n",
    "        ]\n",
    "\n",
    "        # Return exactly the requested n-gram length\n",
    "        return ' '.join(words[:length])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "377bca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from insults lion's ruinate shook age\n",
      "heart highmost except firstborn loan; pitch [144]\n",
      "wasted firm dreading herd false-speaking millioned stormy withal\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print(generate_ngram('from', 'increase', 6, 'COMPLETE', 100))\n",
    "print(generate_ngram('thy', 'heart', 7, 'START', 100))\n",
    "print(generate_ngram('love', 'time', 8, 'MIDDLE', 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763d57a",
   "metadata": {},
   "source": [
    "Not bad at all, we are finally generating sentences that adhere to our word count guidance. However, we dont seem to have a control over which word from the three words we provide gets added to the line. but the sentences look semamntically sound compared to our previous attempt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c233e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from sap tiger's pierced shook age\n",
      "from ate shamefully tear shook age\n",
      "from sap shamefully tear shook age\n"
     ]
    }
   ],
   "source": [
    "# Generate same conditioning 3 times\n",
    "for i in range(3):\n",
    "    print(generate_ngram('from', 'increase', 6, 'COMPLETE'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64edb64",
   "metadata": {},
   "source": [
    "It usually seems to fallback on repetition with a few minor modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fe691f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate's until except loan; loan; be; mind: until\n",
      "beauty trophies steep-up sharp'st firstborn speed: unrespected; until\n",
      "hied dancing chips deeds; composition grievances long-lived over\n"
     ]
    }
   ],
   "source": [
    "print(generate_ngram('thy', 'love', 8, 'START'))\n",
    "print(generate_ngram('when', 'beauty', 8, 'MIDDLE'))  \n",
    "print(generate_ngram('but', 'death', 8, 'END'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a01aa",
   "metadata": {},
   "source": [
    "let us add a cleaning utility which replaces any special characters denoised and a sonnet generator that takes what our ngram generator did except expand it to a 14 line sonnet with proper formatting. We only input the prompt words and based on the structure of the sonnet to be produced, we add the remaining position and word count embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198738ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Remove special characters and clean spacing\"\"\"\n",
    "    # Replace special chars with comma\n",
    "    text = text.replace('[', ',').replace(']', ',').replace('#', ',')\n",
    "    text = text.replace('(', ',').replace(')', ',').replace('{', ',').replace('}', ',')\n",
    "    \n",
    "    # Fix multiple commas and spaces\n",
    "    while ',,' in text:\n",
    "        text = text.replace(',,', ',')\n",
    "    while '  ' in text:\n",
    "        text = text.replace('  ', ' ')\n",
    "    \n",
    "    # Clean edges\n",
    "    text = text.strip(' ,.')\n",
    "    \n",
    "    # Capitalize first letter\n",
    "    if text:\n",
    "        text = text[0].upper() + text[1:]\n",
    "    \n",
    "    return text\n",
    "\n",
    "def generate_sonnet(prompt_words, num_steps=100):\n",
    "    \"\"\"\n",
    "    Generate 14-line Shakespearean sonnet.\n",
    "    \n",
    "    Args:\n",
    "        prompt_words: list of 2-3 thematic words for the sonnet\n",
    "        num_steps: DDIM denoising steps\n",
    "    \n",
    "    Returns:\n",
    "        Formatted sonnet string\n",
    "    \"\"\"\n",
    "    diffusion_model.eval()\n",
    "    \n",
    "    # Extract prompt word IDs\n",
    "    prompt_ids = [word2id.get(w.lower(), UNK_ID) for w in prompt_words[:3]]\n",
    "    while len(prompt_ids) < 3:\n",
    "        prompt_ids.append(UNK_ID)\n",
    "    \n",
    "    # Generate 14 lines with appropriate positions\n",
    "    lines = []\n",
    "    \n",
    "    for line_idx in range(14):\n",
    "        with torch.no_grad():\n",
    "            # Determine position based on line number\n",
    "            if line_idx == 0:\n",
    "                position = 0  # START of sonnet\n",
    "                length = 8\n",
    "                first_id = prompt_ids[0]\n",
    "                last_id = prompt_ids[1]\n",
    "            elif line_idx == 13:\n",
    "                position = 2  # END of sonnet\n",
    "                length = 8\n",
    "                first_id = prompt_ids[2]\n",
    "                last_id = prompt_ids[0]\n",
    "            elif line_idx in [3, 7, 11]:\n",
    "                position = 2  # END of quatrain\n",
    "                length = 8\n",
    "                # Use prompt words in rotation\n",
    "                first_id = prompt_ids[line_idx % 3]\n",
    "                last_id = prompt_ids[(line_idx + 1) % 3]\n",
    "            else:\n",
    "                position = 1  # MIDDLE of quatrain\n",
    "                length = 8\n",
    "                first_id = prompt_ids[line_idx % 3]\n",
    "                last_id = prompt_ids[(line_idx + 2) % 3]\n",
    "            \n",
    "            # Build conditioning\n",
    "            len_emb = length_embeddings(torch.tensor(length).to(device))\n",
    "            pos_emb = position_embeddings(torch.tensor(position).to(device))\n",
    "            first_emb = text_embeddings(torch.tensor(first_id).to(device))\n",
    "            last_emb = text_embeddings(torch.tensor(last_id).to(device))\n",
    "            \n",
    "            conditioning = torch.stack([len_emb, pos_emb, first_emb, last_emb]).unsqueeze(0)\n",
    "            \n",
    "            # Generate\n",
    "            latent = torch.randn(1, 20, 768).to(device)\n",
    "            inference_scheduler.set_timesteps(num_steps)\n",
    "            \n",
    "            for t in inference_scheduler.timesteps:\n",
    "                noise_pred = diffusion_model(latent, torch.tensor([t]).to(device), conditioning)\n",
    "                latent = inference_scheduler.step(noise_pred, t, latent).prev_sample\n",
    "            \n",
    "            # Decode\n",
    "            logits = torch.matmul(latent, text_embeddings.weight.T)\n",
    "            token_ids = logits.argmax(dim=-1)[0]\n",
    "            \n",
    "            words = [id2word[idx.item()] for idx in token_ids if idx.item() in id2word and id2word[idx.item()] != '<PAD>']\n",
    "            line_text = ' '.join(words[:length])\n",
    "            line_text = clean_text(line_text)\n",
    "            \n",
    "            lines.append(line_text)\n",
    "    \n",
    "    # Format sonnet with quatrain breaks\n",
    "    formatted = []\n",
    "    for i, line in enumerate(lines):\n",
    "        formatted.append(line)\n",
    "        if i in [3, 7, 11]:\n",
    "            formatted.append('')\n",
    "    \n",
    "    return '\\n'.join(formatted)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "505e0351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time sunset accidents proceed elsewhere; life's outbraves dwell;\n",
      "Wasted millioned praise; store; false-speaking prefiguring; stormy withal\n",
      "The lords abide; surly firstborn prefiguring; least; withal\n",
      "Steep-up millioned \"kind part: withal part: quill exchanged\n",
      "\n",
      "Wasted firm praise; herd twofold sing; stormy withal\n",
      "Such lords dreading surly firstborn speed: white; withal\n",
      "Niggard sharp'st charged; sharp'st beated mind: ye: outbraves\n",
      "Beautiful wrackful steep-up lay; withal zealous quill withal\n",
      "\n",
      "The lords dreading surly firstborn prefiguring; unrespected; withal\n",
      "Niggard sharp'st charged; sharp'st beated speed: true: outbraves\n",
      "Wasted firm praise; surly twofold sing; stormy exchanged\n",
      "At sharp'st steep-up lay; touched zealous quill outbraves\n",
      "\n",
      "Together intents charged; sharp'st firstborn lay; white; miscalled\n",
      "Precious owner's ! dross; composition grievances quill withal\n"
     ]
    }
   ],
   "source": [
    "sonnet = generate_sonnet(['love', 'time', 'beauty'], num_steps=100)\n",
    "print(sonnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06c0781",
   "metadata": {},
   "source": [
    "let us test at a higher number of denoising steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8af170a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time lion's accidents proceed loan; life's will; outbraves\n",
      "Wasted firm ye: will; twofold sing; stormy withal\n",
      "The lords dreading surly firstborn prefiguring; least; withal\n",
      "Steep-up blow ye: store; withal mind: spoils withal\n",
      "\n",
      "Wasted firm praise; surly false-speaking distance stormy withal\n",
      "The lords bevel; surly firstborn speed: least; withal\n",
      "Wisdom center steep-up sharp'st beated prefiguring; unrespected; tan\n",
      "Precious wights steep-up lay; withal prefiguring; quill withal\n",
      "\n",
      "The lords dreading 'cide firstborn prefiguring; white; withal\n",
      "Present'st sharp'st charged; dross; beated prefiguring; unrespected; outbraves\n",
      "Wasted firm praise; surly false-speaking prefiguring; stormy withal\n",
      "Beautiful life's store; subsist; deeds; life's quill outbraves\n",
      "\n",
      "Niggard dust steep-up sharp'st tan sing; unrespected; miscalled\n",
      "At sharp'st be; lay; touched grievances apple outbraves\n"
     ]
    }
   ],
   "source": [
    "sonnet = generate_sonnet(['love', 'time', 'beauty'], num_steps=300)\n",
    "print(sonnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab68eb6",
   "metadata": {},
   "source": [
    "there is some repetition for some tokens but we beleive the lower number of steps produced a better diversity of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8933ec28",
   "metadata": {},
   "source": [
    "let us train for another 100 epochs, we weight the reconstruction loss by 0.5 so we force our model to focus on the reconstruction task more than diffusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "934da6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/150: 100%|██████████| 1889/1889 [04:28<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Diff=0.4707 Recon=1.4701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/150: 100%|██████████| 1889/1889 [04:33<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Diff=0.4761 Recon=1.4346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/150: 100%|██████████| 1889/1889 [04:26<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Diff=0.4790 Recon=1.4049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/150: 100%|██████████| 1889/1889 [04:16<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Diff=0.4802 Recon=1.3841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/150: 100%|██████████| 1889/1889 [04:32<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Diff=0.4788 Recon=1.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/150: 100%|██████████| 1889/1889 [04:22<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Diff=0.4800 Recon=1.3375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/150: 100%|██████████| 1889/1889 [04:25<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Diff=0.4768 Recon=1.3046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/150: 100%|██████████| 1889/1889 [04:29<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Diff=0.4730 Recon=1.2832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/150: 100%|██████████| 1889/1889 [04:28<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Diff=0.4733 Recon=1.2638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/150: 100%|██████████| 1889/1889 [04:28<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Diff=0.4711 Recon=1.2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/150: 100%|██████████| 1889/1889 [04:28<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Diff=0.4685 Recon=1.2160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/150: 100%|██████████| 1889/1889 [04:22<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Diff=0.4663 Recon=1.1964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/150: 100%|██████████| 1889/1889 [04:20<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Diff=0.4633 Recon=1.1694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/150: 100%|██████████| 1889/1889 [04:26<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Diff=0.4622 Recon=1.1597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/150: 100%|██████████| 1889/1889 [04:27<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Diff=0.4593 Recon=1.1368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/150: 100%|██████████| 1889/1889 [04:26<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Diff=0.4566 Recon=1.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/150: 100%|██████████| 1889/1889 [04:28<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Diff=0.4547 Recon=1.0926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/150: 100%|██████████| 1889/1889 [04:26<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Diff=0.4518 Recon=1.0774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/150: 100%|██████████| 1889/1889 [04:26<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Diff=0.4490 Recon=1.0602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/150: 100%|██████████| 1889/1889 [04:25<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Diff=0.4473 Recon=1.0318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/150: 100%|██████████| 1889/1889 [04:29<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Diff=0.4452 Recon=1.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/150: 100%|██████████| 1889/1889 [04:29<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Diff=0.4421 Recon=1.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/150: 100%|██████████| 1889/1889 [04:28<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Diff=0.4391 Recon=0.9882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/150: 100%|██████████| 1889/1889 [04:24<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Diff=0.4381 Recon=0.9726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/150: 100%|██████████| 1889/1889 [04:26<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Diff=0.4359 Recon=0.9536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/150: 100%|██████████| 1889/1889 [04:34<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Diff=0.4321 Recon=0.9353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Diff=0.4311 Recon=0.9232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Diff=0.4321 Recon=0.9185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: Diff=0.4279 Recon=0.8946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Diff=0.4265 Recon=0.8817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/150: 100%|██████████| 1889/1889 [04:24<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Diff=0.4259 Recon=0.8720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/150: 100%|██████████| 1889/1889 [04:24<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: Diff=0.4218 Recon=0.8609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: Diff=0.4216 Recon=0.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/150: 100%|██████████| 1889/1889 [04:24<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: Diff=0.4205 Recon=0.8324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Diff=0.4204 Recon=0.8276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: Diff=0.4186 Recon=0.8275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Diff=0.4187 Recon=0.8157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Diff=0.4165 Recon=0.8068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Diff=0.4162 Recon=0.7961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Diff=0.4148 Recon=0.7998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Diff=0.4145 Recon=0.7909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Diff=0.4135 Recon=0.7803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Diff=0.4138 Recon=0.7847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Diff=0.4131 Recon=0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: Diff=0.4124 Recon=0.7728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: Diff=0.4127 Recon=0.7714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Diff=0.4130 Recon=0.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: Diff=0.4121 Recon=0.7694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Diff=0.4106 Recon=0.7645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Diff=0.4117 Recon=0.7658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101/150: 100%|██████████| 1889/1889 [04:24<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: Diff=0.4102 Recon=0.7606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102: Diff=0.4104 Recon=0.7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103: Diff=0.4101 Recon=0.7567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104: Diff=0.4099 Recon=0.7599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105: Diff=0.4104 Recon=0.7550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106: Diff=0.4107 Recon=0.7569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107: Diff=0.4098 Recon=0.7552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108: Diff=0.4094 Recon=0.7513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109: Diff=0.4094 Recon=0.7533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110/150: 100%|██████████| 1889/1889 [04:24<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110: Diff=0.4094 Recon=0.7578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111: Diff=0.4094 Recon=0.7544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112: Diff=0.4084 Recon=0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113: Diff=0.4087 Recon=0.7502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114: Diff=0.4075 Recon=0.7518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115/150: 100%|██████████| 1889/1889 [04:22<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115: Diff=0.4069 Recon=0.7516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116: Diff=0.4070 Recon=0.7629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117: Diff=0.4070 Recon=0.7513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118: Diff=0.4066 Recon=0.7518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: Diff=0.4067 Recon=0.7551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120: Diff=0.4052 Recon=0.7575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121: Diff=0.4051 Recon=0.7610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122: Diff=0.4054 Recon=0.7671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 123/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123: Diff=0.4042 Recon=0.7581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124/150: 100%|██████████| 1889/1889 [04:24<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124: Diff=0.4063 Recon=0.7634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125/150: 100%|██████████| 1889/1889 [04:24<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125: Diff=0.4039 Recon=0.7598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 126/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126: Diff=0.4055 Recon=0.7687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127: Diff=0.4063 Recon=0.7679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 128/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128: Diff=0.4060 Recon=0.7705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129/150: 100%|██████████| 1889/1889 [04:24<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129: Diff=0.4063 Recon=0.7720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 130/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130: Diff=0.4081 Recon=0.7777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 131/150: 100%|██████████| 1889/1889 [04:22<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131: Diff=0.4074 Recon=0.7744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 132/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132: Diff=0.4089 Recon=0.7793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 133/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133: Diff=0.4091 Recon=0.7796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 134/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134: Diff=0.4112 Recon=0.7829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 135/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135: Diff=0.4123 Recon=0.7823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 136/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136: Diff=0.4156 Recon=0.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137: Diff=0.4154 Recon=0.7909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 138/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138: Diff=0.4171 Recon=0.7914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139: Diff=0.4199 Recon=0.8045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 140/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140: Diff=0.4233 Recon=0.8123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 141/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141: Diff=0.4249 Recon=0.8087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 142/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142: Diff=0.4266 Recon=0.8184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 143/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143: Diff=0.4308 Recon=0.8135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 144/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144: Diff=0.4327 Recon=0.8262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145: Diff=0.4346 Recon=0.8336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 146/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146: Diff=0.4383 Recon=0.8296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 147/150: 100%|██████████| 1889/1889 [04:22<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147: Diff=0.4424 Recon=0.8385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 148/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148: Diff=0.4453 Recon=0.8484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: Diff=0.4501 Recon=0.8496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150/150: 100%|██████████| 1889/1889 [04:23<00:00,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150: Diff=0.4508 Recon=0.8562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50, 150):\n",
    "    epoch_diff = 0\n",
    "    epoch_recon = 0\n",
    "    \n",
    "    for batch in tqdm(ngram_loader, desc=f\"Epoch {epoch+1}/150\"):\n",
    "        token_ids = batch['token_ids'].to(device)\n",
    "        conditioning = batch['conditioning'].to(device)\n",
    "        \n",
    "        clean_embeddings = text_embeddings(token_ids)\n",
    "        timesteps = torch.randint(0, 1000, (clean_embeddings.shape[0],)).to(device)\n",
    "        noise = torch.randn_like(clean_embeddings)\n",
    "        noisy_embeddings = train_scheduler.add_noise(clean_embeddings, noise, timesteps)\n",
    "        \n",
    "        predicted_noise = diffusion_model(noisy_embeddings, timesteps, conditioning)\n",
    "        diffusion_loss = F.mse_loss(predicted_noise, noise)\n",
    "        \n",
    "        alpha_prod = train_scheduler.alphas_cumprod[timesteps].view(-1, 1, 1)\n",
    "        denoised = (noisy_embeddings - torch.sqrt(1 - alpha_prod) * predicted_noise) / torch.sqrt(alpha_prod)\n",
    "        denoised = torch.clamp(denoised, -3, 3)\n",
    "        \n",
    "        logits = torch.matmul(denoised, text_embeddings.weight.T)\n",
    "        reconstruction_loss = F.cross_entropy(logits.reshape(-1, vocab_size), token_ids.reshape(-1), ignore_index=PAD_ID)\n",
    "        \n",
    "        total_loss = diffusion_loss + 0.5 * reconstruction_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            list(text_embeddings.parameters()) + list(length_embeddings.parameters()) + \n",
    "            list(position_embeddings.parameters()) + list(diffusion_model.parameters()), max_norm=1.0\n",
    "        )\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_diff += diffusion_loss.item()\n",
    "        epoch_recon += reconstruction_loss.item()\n",
    "    \n",
    "    avg_diff = epoch_diff / len(ngram_loader)\n",
    "    avg_recon = epoch_recon / len(ngram_loader)\n",
    "    \n",
    "    ngram_history['epoch'].append(epoch + 1)\n",
    "    ngram_history['diffusion_loss'].append(avg_diff)\n",
    "    ngram_history['reconstruction_loss'].append(avg_recon)\n",
    "    ngram_history['total_loss'].append(avg_diff + 0.5 * avg_recon)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Diff={avg_diff:.4f} Recon={avg_recon:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ac9a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'text_embeddings': text_embeddings.state_dict(),\n",
    "    'length_embeddings': length_embeddings.state_dict(),\n",
    "    'position_embeddings': position_embeddings.state_dict(),\n",
    "    'diffusion_model': diffusion_model.state_dict(),\n",
    "    'vocab': {'word2id': word2id, 'id2word': id2word},\n",
    "    'history': ngram_history\n",
    "}, 'ngram_model_epoch150.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00164b5a",
   "metadata": {},
   "source": [
    "**let us plot our progress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc60a469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(ngram_history['epoch'], ngram_history['diffusion_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Diffusion Loss')\n",
    "plt.title('Diffusion Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(ngram_history['epoch'], ngram_history['reconstruction_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Reconstruction Loss')\n",
    "plt.title('Reconstruction Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(ngram_history['epoch'], ngram_history['total_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.title('Total Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7032b209",
   "metadata": {},
   "source": [
    "we see a sharp rise in diffusion loss and a sudden blip in reconstruction loss at the moment where we increased reconstruction loss weights. We seem to have plateaued and even gained some of the loss back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f79f2ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buried acceptable remove elder captive junes familiar lying\n",
      "Thou best though dressing wood candles privilege; unswayed\n",
      "Thou felt at dressing chaste familiar increase; but\n",
      "Delayed dial's composition bitter o'ersways life's neck redeem\n",
      "\n",
      "My best must dressing wood fire--my privilege; unswayed\n",
      "Thou felt at dressing affable familiar ruminate but\n",
      "To forests height hied busy fleece speed: hied\n",
      "The delayed distempered credit torture smiling gazing redeem\n",
      "\n",
      "Thou felt at dressing affable familiar ruminate but\n",
      "To forests user dressing busy fleece truest hied\n",
      "My best must dressing wood candles privilege; unswayed\n",
      "Her little offenses burdens age's life's hated hied\n",
      "\n",
      "The forests feathered dressing busy fleece truest hied\n",
      "The little offenses outbraves wretch's life's remove hied\n"
     ]
    }
   ],
   "source": [
    "sonnet = generate_sonnet(['love', 'time', 'beauty'], num_steps=100)\n",
    "print(sonnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea6850",
   "metadata": {},
   "source": [
    "The model was more creative at 50 epochs, let us test at lower denoising steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8828859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love resty favorites thy hate's new-appearing life's shamefully\n",
      "Hate farewell receives guest hammered candles candles shamefully\n",
      "She quenched no acquainted older favor thrice harvest\n",
      "Delayed pitied endowed delayed water urge variation or\n",
      "\n",
      "Hate although receives guest hammered fire--my candles dreading\n",
      "You quenched no guest older favor thrice pleasant\n",
      "My weakness might touch sad thunder spring; selfsame\n",
      "Said grant despised forbear o'ersways stand inherit your\n",
      "\n",
      "She hated no flow older favor thrice selfsame\n",
      "My weakness making touch drooping thunder spring; selfsame\n",
      "Hate farewell receives report hammered candles rudely shamefully\n",
      "Sorry sour making wail an strange dreading league\n",
      "\n",
      "My weakness might touch sins thunder spring; selfsame\n",
      "Sorry sour delayed despised an transgression dreading clean\n"
     ]
    }
   ],
   "source": [
    "sonnet = generate_sonnet(['love', 'hate', 'killed'], num_steps=50)\n",
    "print(sonnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1293b631",
   "metadata": {},
   "source": [
    "much better, i believe our model even though upon random sampling of time steps, has learned to denoise well from a lower number. let us try 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d31b35d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sad enforced at torture fierce riches composition\n",
      "Hell adieu than captive autumn sacred seal dearer;\n",
      "My best making dressing wood candles ground; unswayed\n",
      "Be counterfeit to another's changing counterfeit tract redeem\n",
      "\n",
      "Time sad to pardon anger sacred thrice answered\n",
      "My best though dressing wood candles .\" unswayed\n",
      "Delayed mounted at hap dart swift seal infant's\n",
      "Delayed millioned answered bitter o'ersways life's neck redeem\n",
      "\n",
      "My best making under wood candles .\" unswayed\n",
      "Delayed mounted lying hap dart swift seal busy\n",
      "To adieu than pardon anger sacred stamped mounted\n",
      "Delayed delayed mounted hap in amiss seal wherein\n",
      "\n",
      "Another's mounted lying pardon dart swift seal busy\n",
      "Delayed elder composition thrivers from amiss seal infant's\n"
     ]
    }
   ],
   "source": [
    "sonnet = generate_sonnet(['hell', 'time', 'love'], num_steps=300)\n",
    "print(sonnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1563f6",
   "metadata": {},
   "source": [
    "Testing at 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f94c16b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Men beauty's taker sap get powerful riches buriest\n",
      "To straight besmeared indirectly crown height thrice me\n",
      "Time sad than hied anger together seal busy\n",
      "To straight fleece woman's present'st counterfeit awards hell\n",
      "\n",
      "By straight besmeared indirectly fore-bemoaned sad thrice muse\n",
      "Time sad than pardon anger uneared thrice mounted\n",
      "Heaven oppression than surly present'st vassal love-kindling holds\n",
      "Old grow from quickly changing counterfeit grounded matter;\n",
      "\n",
      "Time adieu though pardon anger sacred thrice mounted\n",
      "Heaven oppression than surly present'st grievances love-kindling blesses\n",
      "My straight besmeared indirectly yellow powerful rarities shop\n",
      "To badness eyelids grievances pure threefold weakness holds\n",
      "\n",
      "Heaven oppression than war's present'st vassal love-kindling blesses\n",
      "To drooping composition grievances pure threefold lameness holds\n"
     ]
    }
   ],
   "source": [
    "sonnet = generate_sonnet(['heaven', 'hell', 'time'], num_steps=150)\n",
    "print(sonnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef1dd5d",
   "metadata": {},
   "source": [
    "Certain sentences are the same, even after different steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc3461ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('ngram_model_epoch50.pt')\n",
    "\n",
    "text_embeddings.load_state_dict(checkpoint['text_embeddings'])\n",
    "length_embeddings.load_state_dict(checkpoint['length_embeddings'])\n",
    "position_embeddings.load_state_dict(checkpoint['position_embeddings'])\n",
    "diffusion_model.load_state_dict(checkpoint['diffusion_model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a9b358e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hell present'st bath wombs inherit stern hill hell\n",
      "Another's bail age's bell inherit sharp'st withal hell\n",
      "Time lords seething surly lily's sharp'st withal hell\n",
      "Death's life's pilgrimage aloft inherit zealous correction hell\n",
      "\n",
      "Ghastly follows age's bell flatterer surly withal flown\n",
      "Time firm waiting surly lily's surly withal hell\n",
      "Wasted firm praise; store; withal prefiguring; stormy withal\n",
      "Death's lords dreading herd intend zealous correction hell\n",
      "\n",
      "Leads lords at surly autumn surly withal hell\n",
      "Wasted decease \"had herd false-speaking sing; stormy exchanged\n",
      "Firm firm age's bell inherit zealous withal hell\n",
      "Lion's ambush ye: mind: withal mind: quill withal\n",
      "\n",
      "Wasted firm dreading store; false-speaking millioned stormy exchanged\n",
      "Lion's millioned \"had part: discontent mind: quill withal\n"
     ]
    }
   ],
   "source": [
    "sonnet = generate_sonnet(['love', 'hell', 'time'], num_steps=120)\n",
    "print(sonnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e452004",
   "metadata": {},
   "source": [
    "testing empty token prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33082e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offender's harsh moan imitate speed: gate; fly forests\n",
      "Forests until silver found: mind: sing; life's forests\n",
      "Forests until treason crooked intents harsh fly forests\n",
      "Alas until treason life's composition gate; zealous forests\n",
      "\n",
      "Forests until treason crooked crossed sing; life's forests\n",
      "Forests until rents store; excellent sing; life's fly\n",
      "Forests until silver store; devil gate; life's forests\n",
      "Forests until treason store; composition gate; zealous sadly\n",
      "\n",
      "Forests until rents store; until sing; life's forests\n",
      "Forests until rents crooked crossed inherit life's forests\n",
      "Forests until blush crooked life's vial; life's sadly\n",
      "Glorious until treason store; composition lips' eisel present'st\n",
      "\n",
      "Forests until rents store; life's gate; recured forests\n",
      "Forests until treason store; composition gate; dearths forests\n"
     ]
    }
   ],
   "source": [
    "sonnet = generate_sonnet([' ', ' ', ' '], num_steps=120)\n",
    "print(sonnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936535ad",
   "metadata": {},
   "source": [
    "lots of repitition, this is probably because, without the conditioning embedding for a start and an end word, the modal cheats to an easier more probable solution made of redundant tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "991e462b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('ngram_model_epoch150.pt')\n",
    "\n",
    "text_embeddings.load_state_dict(checkpoint['text_embeddings'])\n",
    "length_embeddings.load_state_dict(checkpoint['length_embeddings'])\n",
    "position_embeddings.load_state_dict(checkpoint['position_embeddings'])\n",
    "diffusion_model.load_state_dict(checkpoint['diffusion_model'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8adbe17",
   "metadata": {},
   "source": [
    "checking the same with 150 epoch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38f88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When termed head than task horse; spring; starved\n",
      "She weakness once sing once taker thrice pleasant\n",
      "She weakness once deserve once familiar thrice pleasant\n",
      "Die dare once forbear making prefiguring; thrice hate's\n",
      "\n",
      "She weakness once sing once taker thrice pleasant\n",
      "She weakness once deserve once strangely thrice pleasant\n",
      "She weakness once deserve once taker thrice pleasant\n",
      "Die if faring forbear once statues thrice hate's\n",
      "\n",
      "Have weakness once acquainted once taker thrice pleasant\n",
      "She weakness once acquainted once taker thrice pleasant\n",
      "She weakness once acquainted once taker thrice pleasant\n",
      "Die though faring forbear once deface thrice hate's\n",
      "\n",
      "Have weakness once sing once nine thrice pleasant\n",
      "Die though faring forbear making deface thrice hate's\n"
     ]
    }
   ],
   "source": [
    "sonnet = generate_sonnet([' ', ' ', ' '], num_steps=120)\n",
    "print(sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d9dece3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> termed head where task horse; spring; pleasant\n",
      "Have weakness once sing once taker thrice pleasant\n",
      "Have weakness once deserve once taker thrice pleasant\n",
      "Die if once forbear making prefiguring; prove; hate's\n",
      "\n",
      "Have weakness once sing once taker thrice pleasant\n",
      "Have weakness once deserve once taker thrice pleasant\n",
      "Have weakness once deserve once taker thrice pleasant\n",
      "Die if once forbear making prefiguring; thrice hate's\n",
      "\n",
      "Have weakness once acquainted once taker thrice pleasant\n",
      "Have weakness once acquainted once taker thrice pleasant\n",
      "Have weakness once acquainted once taker thrice pleasant\n",
      "Die if once forbear making statues thrice hate's\n",
      "\n",
      "Have weakness once sing once taker thrice pleasant\n",
      "Die if once forbear making statues thrice hate's\n"
     ]
    }
   ],
   "source": [
    "sonnet = generate_sonnet([' ', ' ', ' '], num_steps=500)\n",
    "print(sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "526d388d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would termed woos than life's credit me to\n",
      "<UNK> love-god mounted than never despised ah and\n",
      "Better love-god never few he despised ah to\n",
      "To neck than tattered burdens delayed owner's high\n",
      "\n",
      "To trifle anything could he despised me my\n",
      "Thou shoot red could wherefore bide not thy\n",
      "She bark once duteous once strangely thrice harvest\n",
      "Your hammered fierce tattered outbraves present'st false-speaking high\n",
      "\n",
      "Have shoot wherefore should he bide not my\n",
      "Have weakness once duteous once nine thrice reckoned\n",
      "Have patience wherefore few he bide ah so\n",
      "Now endowed faring married complexioned willingly thrice your\n",
      "\n",
      "Have weakness once pass once nine thrice starved\n",
      "Character though sad herald complexioned statues spring; and\n"
     ]
    }
   ],
   "source": [
    "sonnet = generate_sonnet([' ', 'high', ' '], num_steps=30)\n",
    "print(sonnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f6c15",
   "metadata": {},
   "source": [
    "This one above is a pretty good one "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39932d07",
   "metadata": {},
   "source": [
    "# CONCLUSION\n",
    "\n",
    "- semantic control is crucial as an embedding when dealing with diffusion on text task. the only way we can achieve coherence in grammar is through more number of samples and a good generalized pattern that can be modified by the model to accomodate for different sentence structures\n",
    "- more data\n",
    "- We still could have experimented with the model hyperparamaters apart from what was provided. Maybe tinkering with the number of channels and attention heads initialized could have provided better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
