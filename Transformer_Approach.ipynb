{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "96d5b08e",
      "metadata": {
        "id": "96d5b08e"
      },
      "source": [
        "## Part 2: Transformer-Based Approach\n",
        "\n",
        "This section implements the conventional approach using transformers to generate Shakespeare sonnets. While the data preprocessing and n-gram methodology remain similar to the diffusion model approach, the key differences lie in the network architecture and training strategy. Unlike diffusion models that denoise embeddings, transformers leverage attention mechanisms to learn sequential dependencies and generate coherent text autoregressively."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tO7v_eKb0yI_",
      "metadata": {
        "id": "tO7v_eKb0yI_"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d149c5e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d149c5e7",
        "outputId": "e8b91d44-e3ee-4638-9d1a-f031b19efb65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.20.0\n"
          ]
        }
      ],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "#import tensorflow_datasets as tfds\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Tensorflow version {}\".format(tf.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebd01d47",
      "metadata": {
        "id": "ebd01d47"
      },
      "source": [
        "Run Below cell for GPU Utilization if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dab85d37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dab85d37",
        "outputId": "ef99f4f5-8e83-44bd-ca13-1ce283c02742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPLICAS: 1\n"
          ]
        }
      ],
      "source": [
        "strategy = tf.distribute.get_strategy()\n",
        "print(\"REPLICAS: {}\".format(strategy.num_replicas_in_sync))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A_8MM0OY1Maz",
      "metadata": {
        "id": "A_8MM0OY1Maz"
      },
      "source": [
        "### **Preprocessing Shakespeare Text**\n",
        "\n",
        "Here we convert punctuations to special symbols remove numbers to focus on words or linguistic patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2dabb74f",
      "metadata": {
        "id": "2dabb74f"
      },
      "outputs": [],
      "source": [
        "def clean_numbers(text):\n",
        "    pattern = r\"[\\d-]\"\n",
        "    return re.sub(pattern, '', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "207c2c63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "207c2c63",
        "outputId": "0930e6c2-db23-4064-e0b2-f6b415f9ad80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading txt file...\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "text = ''\n",
        "print( \"Reading txt file...\")\n",
        "#with open('D:/user/docs/NU/_Info6106/Lecture 10/data/shakespeare-sonnets.txt', 'r') as f:\n",
        "with open('data/shakespeare-sonnets.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# sentence delimiter processing\n",
        "text = text.replace(\",\\n\", \" _eol_ \")\n",
        "text = text.replace(\",\", \" _comma_  \")\n",
        "# text = text.replace(\":\", \" _comma_  \")\n",
        "text = text.replace(\";\", \" _comma_  \")\n",
        "\n",
        "text = text.replace(\"?\\n\", \". \")\n",
        "text = text.replace(\"!\\n\", \". \")\n",
        "text = text.replace(\".\\n\", \". \")\n",
        "text = text.replace(\"?\", \".\")\n",
        "text = text.replace(\"!\", \".\")\n",
        "text = text.replace(\":\", \".\")\n",
        "\n",
        "text = text.replace('\"',\"\")\n",
        "\n",
        "# i leave apostrophes in place, spawning separate words\n",
        "#text = text.replace(\"’\",\"\")\n",
        "\n",
        "# absorb tabs\n",
        "text = text.replace(\"\\t\", \"\")\n",
        "text = text.replace(\"  \", \"\")\n",
        "\n",
        "# remove numbes\n",
        "text = clean_numbers(text)\n",
        "\n",
        "# absorb soace\n",
        "_RE_COMBINE_WHITESPACE = re.compile(r\"\\s+\")\n",
        "text = _RE_COMBINE_WHITESPACE.sub(\" \", text).strip()\n",
        "\n",
        "# removing contractions\n",
        "text = re.sub(r\"i'm\", \"i am\", text)\n",
        "text = re.sub(r\"he's\", \"he is\", text)\n",
        "text = re.sub(r\"she's\", \"she is\", text)\n",
        "text = re.sub(r\"it's\", \"it is\", text)\n",
        "text = re.sub(r\"that's\", \"that is\", text)\n",
        "text = re.sub(r\"what's\", \"that is\", text)\n",
        "text = re.sub(r\"where's\", \"where is\", text)\n",
        "text = re.sub(r\"how's\", \"how is\", text)\n",
        "text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "text = re.sub(r\"\\'re\", \" are\", text)\n",
        "text = re.sub(r\"\\'d\", \" would\", text)\n",
        "text = re.sub(r\"\\'re\", \" are\", text)\n",
        "text = re.sub(r\"won't\", \"will not\", text)\n",
        "text = re.sub(r\"can't\", \"cannot\", text)\n",
        "text = re.sub(r\"n't\", \" not\", text)\n",
        "text = re.sub(r\"n'\", \"ng\", text)\n",
        "text = re.sub(r\"'bout\", \"about\", text)\n",
        "\n",
        "print('done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c85bb203",
      "metadata": {
        "id": "c85bb203"
      },
      "outputs": [],
      "source": [
        "text = text.lower()\n",
        "text = text.replace('i ', 'I ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "10a22a9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10a22a9a",
        "outputId": "b74641d6-886c-49e5-95c7-e1c3913a8402"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "106075"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a84feb0",
      "metadata": {
        "id": "5a84feb0"
      },
      "source": [
        "### Creating Ngrams from the text\n",
        "\n",
        "Since we are working to train the model to create poems or sonnets from shakespeare text, we use ngrams to structutre our dataset to help the model understand how a poem normally starts and ends as well as what words follow other words.\n",
        "\n",
        "Having this type of dataset is especially important when we are training in poems as the sentence strucutre do not follow the norm and it is difficult to understand the pattern of each sentence. So having multiple examples of differant sequence lengths is really helpful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "02943d37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02943d37",
        "outputId": "7f2e9628-c6e5-42fb-ef1c-6cb7c81daed7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 6/19 [00:00<00:00, 57.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ngram- 2 length: 14004\n",
            "ngram- 3 length: 18742\n",
            "ngram- 4 length: 19387\n",
            "ngram- 5 length: 19468\n",
            "ngram- 6 length: 19493\n",
            "ngram- 7 length: 19508\n",
            "ngram- 8 length: 19521\n",
            "ngram- 9 length: 19532\n",
            "ngram- 10 length: 19542\n",
            "ngram- 11 length: 19552\n",
            "ngram- 12 length: 19559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:00<00:00, 47.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ngram- 13 length: 19566\n",
            "ngram- 14 length: 19573\n",
            "ngram- 15 length: 19579\n",
            "ngram- 16 length: 19584\n",
            "ngram- 17 length: 19587\n",
            "ngram- 18 length: 19589\n",
            "ngram- 19 length: 19591\n",
            "ngram- 20 length: 19592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "\n",
        "ngrams_up_to_20 = []\n",
        "for i in tqdm(range(2, 21)):\n",
        "    ngram_counts = Counter(ngrams(text.split(), i))\n",
        "    print('ngram-', i, 'length:', len(ngram_counts))\n",
        "    ngrams_up_to_20.append(ngram_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "28688a95",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28688a95",
        "outputId": "240c195f-c239-478c-e0b4-94c12736e569"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(('_comma_', 'why', 'dost', 'thou'), 3),\n",
              " (('when', 'I', 'have', 'seen'), 3),\n",
              " (('_comma_', 'some', 'in', 'their'), 3),\n",
              " (('_eol_', 'some', 'in', 'their'), 3),\n",
              " (('fair', '_comma_', 'kind', '_comma_'), 3),\n",
              " (('_comma_', 'kind', '_comma_', 'and'), 3),\n",
              " (('kind', '_comma_', 'and', 'true'), 3),\n",
              " (('for', 'I', 'have', 'sworn'), 3),\n",
              " (('the', 'treasure', 'of', 'thy'), 2),\n",
              " (('is', 'the', 'time', 'that'), 2)]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ngrams_up_to_20[2].most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ca3911ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca3911ab",
        "outputId": "3ea722ea-06d2-450e-8f2a-f1eec3b756f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"from fairest creatures we desire increase _eol_ that thereby beauty's rose might never die _eol_ but _comma_ as the riper should by time decease _eol_ his tender heir might bear his memory\",\n",
              " \"but thou _comma_ contracted to thine own bright eyes _eol_ feed'st thy light's flame with selfsubstantial fuel _eol_ making a famine where abundance lies _eol_ thyself thy foe _comma_ to thy sweet self too cruel\",\n",
              " \"thou that art now the world's fresh ornament and only herald to the gaudy spring within thine own bud buriest thy content and _comma_ tender churl _comma_ mak'st waste in niggarding\",\n",
              " \"pity the world _comma_ or else this glutton be to eat the world's due _comma_ by the grave and thee\"]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data = text.split('.')\n",
        "for i in range(len(training_data)):\n",
        "    training_data[i] = training_data[i].strip()\n",
        "training_data[0:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1c694627",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c694627",
        "outputId": "955a8649-9969-41b8-a186-20011c64cc87"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3228"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dictionary = set()\n",
        "for s in training_data:\n",
        "    words = s.split()\n",
        "    for word in words:\n",
        "        dictionary.add(word)\n",
        "\n",
        "len(dictionary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0329a90d",
      "metadata": {
        "id": "0329a90d"
      },
      "source": [
        "#### Tokenizer\n",
        "\n",
        "- We use Keras Tokenizer to create word-to-integer mappings\n",
        "- VOCAB_SIZE includes START_TOKEN and END_TOKEN for sequence boundaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "18c4559f",
      "metadata": {
        "id": "18c4559f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "364ec33e",
      "metadata": {
        "id": "364ec33e"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Set the maximum sequence length for padding\n",
        "max_sequence_length = 50\n",
        "\n",
        "# Fit the tokenizer on the training data\n",
        "tokenizer.fit_on_texts(training_data)\n",
        "\n",
        "# Convert the training data into sequences of tokens\n",
        "sequences = tokenizer.texts_to_sequences(training_data)\n",
        "\n",
        "# Pad the sequences to have the same length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c900a4c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c900a4c0",
        "outputId": "1f2c0333-402f-4d4b-c97d-524bb9229f44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3230, 3228, 3229)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define start and end token to indicate the start and end of a sentence\n",
        "START_TOKEN, END_TOKEN = len(dictionary), len(dictionary) + 1\n",
        "\n",
        "# Vocabulary size plus start and end token\n",
        "VOCAB_SIZE = len(dictionary) + 2\n",
        "\n",
        "VOCAB_SIZE, START_TOKEN, END_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BO_uJ1eo6j_y",
      "metadata": {
        "id": "BO_uJ1eo6j_y"
      },
      "source": [
        "Filter out ngrams that are at the end of sentences (We add end of sentance examples later)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2db7e635",
      "metadata": {
        "id": "2db7e635"
      },
      "outputs": [],
      "source": [
        "def remove_periods(ngram):\n",
        "    for wrd in ngram[0]:\n",
        "        if '.' in wrd or \"’\" in wrd or \"‘\" in wrd:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def my_filter(ngrams):\n",
        "    return filter(remove_periods, ngrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0204ebc3",
      "metadata": {
        "id": "0204ebc3"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def fisher_yates (arr1, arr2):\n",
        "\n",
        "    # We will Start from the last element\n",
        "    # and swap one by one.\n",
        "    n = len(arr1)\n",
        "    if n != len(arr2):\n",
        "        return None\n",
        "\n",
        "    for i in range(n - 1, 0, -1):\n",
        "\n",
        "        # Pick a random index from 0 to i\n",
        "        j = random.randint(0, i)\n",
        "        #print(i, j)\n",
        "\n",
        "        # Swap arr[i] with the element at random index\n",
        "        arr1[i], arr1[j] = arr1[j], arr1[i]\n",
        "        arr2[i], arr2[j] = arr2[j], arr2[i]\n",
        "\n",
        "    return arr1, arr2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eLMi4Pfv60nu",
      "metadata": {
        "id": "eLMi4Pfv60nu"
      },
      "source": [
        "In the below cells first words examples, end of sentance examples and our ngram examples with the above mentioned filter applied are all created and added to our dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fa8dec3",
      "metadata": {
        "id": "8fa8dec3"
      },
      "source": [
        "#### First words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e8e2a732",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8e2a732",
        "outputId": "4871f5ce-5e04-45f3-aaa9-aff15c33e6c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:1: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:1: SyntaxWarning: invalid escape sequence '\\.'\n",
            "C:\\Users\\yohan\\AppData\\Local\\Temp\\ipykernel_24392\\1984571126.py:1: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  first_word_counts = Counter([ p.replace('. ', '') for p in re.findall('\\..[^\" \"]*', text.lower())])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('o', 49),\n",
              " ('but', 41),\n",
              " ('for', 31),\n",
              " ('then', 25),\n",
              " ('so', 24),\n",
              " ('the', 24),\n",
              " ('if', 23),\n",
              " ('i', 20),\n",
              " ('and', 17),\n",
              " ('how', 15)]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_word_counts = Counter([ p.replace('. ', '') for p in re.findall('\\..[^\" \"]*', text.lower())])\n",
        "first_word_counts.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "29f49875",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29f49875",
        "outputId": "e5c90175-e72f-479f-b843-48747de7f672"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([[3228], [3228], [3228], [3228], [3228]], [[58], [8], [8], [19], [8]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train = [[tokenizer.word_index[w[0]]] for w,_ in first_word_counts.most_common() if w[0] in tokenizer.word_index and w[0] != '[]']\n",
        "X_train = [[START_TOKEN] for i in range(len(y_train))]\n",
        "\n",
        "X_train[0:5], y_train[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbabf547",
      "metadata": {
        "id": "cbabf547"
      },
      "source": [
        "**Adding Bigrams**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d278932a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d278932a",
        "outputId": "8450efd0-0eb5-4a5d-a095-6b0918fb3949"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('_eol_', 'and'), 150)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ngrams_up_to_20[0].most_common()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "73b95c3d",
      "metadata": {
        "id": "73b95c3d"
      },
      "outputs": [],
      "source": [
        "bigrams_to_learn = ngrams_up_to_20[0]\n",
        "X_train_2 = [[tokenizer.word_index[sent[0][0]]] for sent in my_filter(bigrams_to_learn.most_common())\n",
        "                  if sent[0][0] in tokenizer.word_index and sent[0][1] in tokenizer.word_index]\n",
        "y_train_2 = [[tokenizer.word_index[sent[0][1]]] for sent in my_filter(bigrams_to_learn.most_common())\n",
        "                  if sent[0][0] in tokenizer.word_index and sent[0][1] in tokenizer.word_index]\n",
        "X_train_2, y_train_2 = fisher_yates(X_train_2, y_train_2)\n",
        "\n",
        "X_train.extend(X_train_2)\n",
        "y_train.extend(y_train_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "06f10714",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06f10714",
        "outputId": "e21ac6cd-700c-4815-c642-52b80dd32d76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[([354], [6]),\n",
              " ([14], [39]),\n",
              " ([27], [613]),\n",
              " ([32], [512]),\n",
              " ([2027], [2028]),\n",
              " ([22], [1254]),\n",
              " ([98], [171]),\n",
              " ([35], [374]),\n",
              " ([38], [216]),\n",
              " ([1050], [2226])]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random.sample(list(zip(X_train, y_train)), 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dee86487",
      "metadata": {
        "id": "dee86487"
      },
      "source": [
        "Rest of ngrams (up to 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "19abd637",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19abd637",
        "outputId": "e8f38795-f9d4-400b-923d-0d1c72fe872b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [00:02<00:00,  6.92it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i in tqdm(range(1, len(ngrams_up_to_20))):\n",
        "    ngrams_to_learn = ngrams_up_to_20[i]\n",
        "    X_train_2 = [[tokenizer.word_index[w] for w in sent[0][:-1]] for sent in my_filter(ngrams_to_learn.most_common())\n",
        "                   if all([w in tokenizer.word_index for w in sent[0]])]\n",
        "    y_train_2 = [[tokenizer.word_index[w] for w in sent[0][1:]] for sent in my_filter(ngrams_to_learn.most_common())\n",
        "                   if all([w in tokenizer.word_index for w in sent[0]])]\n",
        "    #X_train_2 = X_train_2[:2000]\n",
        "    #y_train_2 = y_train_2[:2000]\n",
        "    X_train_2, y_train_2 = fisher_yates(X_train_2, y_train_2)\n",
        "    X_train.extend(X_train_2)\n",
        "    y_train.extend(y_train_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1a51b17f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a51b17f",
        "outputId": "db6c6fb1-0157-4bf2-9e13-165592f104c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(61550, 61550)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train), len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "07232e39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07232e39",
        "outputId": "6832119d-f9e9-4a53-bb05-abc72eb1ccc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[([10, 11, 234, 3, 155, 4, 131, 12, 1408, 62, 14, 4, 51, 9, 131, 64, 216], [11, 234, 3, 155, 4, 131, 12, 1408, 62, 14, 4, 51, 9, 131, 64, 216, 235]), ([2928, 2929, 4, 2930, 924, 9], [2929, 4, 2930, 924, 9, 47]), ([65, 85, 880, 1388], [85, 880, 1388, 11]), ([567, 6], [6, 768]), ([608, 5, 259, 6, 1369, 448, 1370, 6, 124, 261, 36, 6], [5, 259, 6, 1369, 448, 1370, 6, 124, 261, 36, 6, 404]), ([305, 10, 593, 11, 1829, 1830, 14, 11, 1831], [10, 593, 11, 1829, 1830, 14, 11, 1831, 3]), ([320, 267, 125, 86, 663, 61, 12, 59, 45, 320, 7], [267, 125, 86, 663, 61, 12, 59, 45, 320, 7, 65]), ([99, 42, 22, 11, 934, 3, 71, 671, 9, 12], [42, 22, 11, 934, 3, 71, 671, 9, 12, 39]), ([1998, 68], [68, 305]), ([97, 257, 22, 23, 11], [257, 22, 23, 11, 97])]\n"
          ]
        }
      ],
      "source": [
        "print(random.sample(list(zip(X_train, y_train)), 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "030cec6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "030cec6c",
        "outputId": "e0d5df14-d35f-45d6-9afb-5cf857e4fceb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['see barren', 'barren of', 'to the edge', 'the edge of']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.sequences_to_texts([[79, 443], [443, 7], [5, 4, 802], [4, 802, 7]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "04ec173e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04ec173e",
        "outputId": "589c3e52-d004-47bd-9276-2727aeb201a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['doth thy lays esteem and gives comma thy lays esteem and gives thy',\n",
              " 'which for memorial comma for memorial still',\n",
              " 'those hours that with gentle work did frame the lovely gaze where every eye doth dwell will comma hours that with gentle work did frame the lovely gaze where every eye doth dwell will play',\n",
              " 'with heavenly comma heavenly alchemy',\n",
              " \"in thy power dost hold time's fickle comma thy power dost hold time's fickle glass\",\n",
              " 'guilt should do thee comma should do thee shame',\n",
              " 'whence hast thou this comma hast thou this becoming',\n",
              " 'their character with golden quill and precious phrase by all comma character with golden quill and precious phrase by all the',\n",
              " 'wardrobe which the robe doth hide to make some special comma which the robe doth hide to make some special instant',\n",
              " 'steals mengs eyes and comma mengs eyes and womengs']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.sequences_to_texts([l[0] + [1] + l[1] for l in random.sample(list(zip(X_train, y_train)), 10)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b6f1720",
      "metadata": {
        "id": "0b6f1720"
      },
      "source": [
        "End of sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c8cd2be0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8cd2be0",
        "outputId": "0497aee3-1b60-4e31-d667-a245ad909ffb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[62, 79, 44, 165, 567, 54, 15, 54, 40, 468]\n"
          ]
        }
      ],
      "source": [
        "print( [tokenizer.word_index[w] for w in training_data[100].replace('_eol_', 'eol').split()] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "680c6bf2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "680c6bf2",
        "outputId": "365746be-e7a8-432a-b2c5-67f62a928dc7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [00:00<00:00, 660.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[12, 59, 113, 3, 79, 11, 285, 1406, 29, 12, 1407, 31, 317], [8, 78, 113], [65, 85, 880, 1388, 11, 881, 3, 1, 312, 882, 1, 883, 314, 10, 1389], [2203, 142, 5, 92, 19, 614, 115, 38, 614, 363, 2, 360, 138, 169, 2204, 127, 235, 1204], [78, 437, 76, 8, 87, 16, 1021, 57, 22, 571], [2, 3, 26, 10, 117, 274, 436, 170, 128], [238, 15, 133, 25, 11, 521, 7, 165], [31, 3, 10, 6, 382], [136, 5, 17, 1, 136, 5, 157, 180, 2, 8, 830, 67, 261, 10, 620, 259], [2595, 6, 706, 491, 429, 2, 2596, 6, 297, 3, 1262, 17, 302]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "last_n_words = []\n",
        "for i in tqdm(range(3, 21)):\n",
        "    tokenized_sentences_500 = random.sample(list(sequences), 500)\n",
        "    for s in tokenized_sentences_500:\n",
        "        last_n_words.append(s[::-1][:i][::-1])\n",
        "\n",
        "print(random.sample(last_n_words, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "06df579c",
      "metadata": {
        "id": "06df579c"
      },
      "outputs": [],
      "source": [
        "X_train_eos = []\n",
        "y_train_eos = []\n",
        "for s in last_n_words:\n",
        "    if 1 < len(s):\n",
        "        X_train_eos.append(s)\n",
        "        y_train_eos.append(s[1:] + [END_TOKEN])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d3a732b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3a732b7",
        "outputId": "26e3210c-a2a1-44fb-dcbc-b8872db07285"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([[112, 3227, 22], [5, 516, 17]], [[3227, 22, 3229], [516, 17, 3229]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_eos[:2], y_train_eos[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5dc58f65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dc58f65",
        "outputId": "4d063eda-06a7-42ad-ac6c-d6fc4035c6de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8985"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train_eos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "d2f895ce",
      "metadata": {
        "id": "d2f895ce"
      },
      "outputs": [],
      "source": [
        "X_train.extend(X_train_eos)\n",
        "y_train.extend(y_train_eos)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2045da8e",
      "metadata": {
        "id": "2045da8e"
      },
      "source": [
        "### Padding\n",
        "Let's pad our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "1ae046e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ae046e8",
        "outputId": "71262570-0088-425a-9511-7ad8b7195303"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max = 0\n",
        "for i in range(len(X_train)):\n",
        "    if max < len(X_train[i]):\n",
        "        max = len(X_train[i])\n",
        "max"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p0wYXmYI-TLB",
      "metadata": {
        "id": "p0wYXmYI-TLB"
      },
      "source": [
        "Almost all sentences are below 20 words so we give 20 as padding value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "0343e7d6",
      "metadata": {
        "id": "0343e7d6"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 20\n",
        "\n",
        "X_train_p = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=MAX_LENGTH, padding='post')\n",
        "y_train_p = tf.keras.preprocessing.sequence.pad_sequences(y_train, maxlen=MAX_LENGTH, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "218639e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "218639e6",
        "outputId": "841d0730-bc2b-4fc5-ed45-5afe9ef4b259"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2287,  289,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_p[20000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "bf795083",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf795083",
        "outputId": "e204a637-1c75-4a16-a3bc-a7a4eb97efb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([289,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0], dtype=int32)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_p[20000]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jNtF8Gw2-2dz",
      "metadata": {
        "id": "jNtF8Gw2-2dz"
      },
      "source": [
        "### Create Final Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "c5KJOkGj_LSh",
      "metadata": {
        "id": "c5KJOkGj_LSh"
      },
      "outputs": [],
      "source": [
        "# For tf.data.Dataset\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q4Bo4VT6_qlf",
      "metadata": {
        "id": "Q4Bo4VT6_qlf"
      },
      "source": [
        "**While creating the dataset:**\n",
        "\n",
        "- The decoder input gets the target sequence up untill but not including the last word\n",
        "- The outputs have all the sequence except the last word\n",
        "\n",
        "This shifted sequence enables proper teacher forcing during training and the decoder predicts the next word given all previous words.\n",
        "\n",
        "The predicted word is compared with the actual target to compute the loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "0d73d64d",
      "metadata": {
        "id": "0d73d64d"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': X_train_p,\n",
        "        # Take everything except the last token for input\n",
        "        'dec_inputs': y_train_p[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        # Take everything except the first token for target (prediction)\n",
        "        'outputs': y_train_p[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "a4a83318",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4a83318",
        "outputId": "5eb9dff0-c1e2-466f-942e-fe47b4510296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input: {'inputs': <tf.Tensor: shape=(64, 20), dtype=int32, numpy=\n",
            "array([[  6,   0,   0, ...,   0,   0,   0],\n",
            "       [ 66,   9,   0, ...,   0,   0,   0],\n",
            "       [349,   0,   0, ...,   0,   0,   0],\n",
            "       ...,\n",
            "       [ 46, 638,   0, ...,   0,   0,   0],\n",
            "       [ 62,  27,   0, ...,   0,   0,   0],\n",
            "       [713,   3,   0, ...,   0,   0,   0]], shape=(64, 20), dtype=int32)>, 'dec_inputs': <tf.Tensor: shape=(64, 19), dtype=int32, numpy=\n",
            "array([[1187,    0,    0, ...,    0,    0,    0],\n",
            "       [   9,  422,    0, ...,    0,    0,    0],\n",
            "       [  55,    0,    0, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [ 638,   61,    0, ...,    0,    0,    0],\n",
            "       [  27,  442,    0, ...,    0,    0,    0],\n",
            "       [   3,  227,    0, ...,    0,    0,    0]],\n",
            "      shape=(64, 19), dtype=int32)>}\n",
            "\n",
            "output: {'outputs': <tf.Tensor: shape=(64, 19), dtype=int32, numpy=\n",
            "array([[  0,   0,   0, ...,   0,   0,   0],\n",
            "       [422,   0,   0, ...,   0,   0,   0],\n",
            "       [  0,   0,   0, ...,   0,   0,   0],\n",
            "       ...,\n",
            "       [ 61,   0,   0, ...,   0,   0,   0],\n",
            "       [442,   0,   0, ...,   0,   0,   0],\n",
            "       [227,   0,   0, ...,   0,   0,   0]], shape=(64, 19), dtype=int32)>}\n"
          ]
        }
      ],
      "source": [
        "for (batch, (inp, tar)) in enumerate(dataset):\n",
        "    print(\"input:\", inp)\n",
        "    print()\n",
        "    print(\"output:\", tar)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e31b5514",
      "metadata": {
        "id": "e31b5514"
      },
      "source": [
        "### Transformer and Model Component Definitions (Object Oriented Aproach)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "fbdeb8eb",
      "metadata": {
        "id": "fbdeb8eb"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(q, k, v, attention_mask=None):\n",
        "    \"\"\"Calculate the attention weights.\n",
        "    q, k, v must have matching leading dimensions.\n",
        "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "    The mask has different shapes depending on its type(padding or look ahead)\n",
        "    but it must be broadcastable for addition.\n",
        "\n",
        "    Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "    output, attention_weights\n",
        "    \"\"\"\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = tf.cast(matmul_qk, tf.float32) / tf.math.sqrt(dk)\n",
        "\n",
        "    # add the mask to the scaled tensor.\n",
        "    if attention_mask is not None:\n",
        "        #scaled_attention_logits += (mask * -1e9)\n",
        "        scaled_attention_logits += (tf.cast(attention_mask, tf.float32) * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1.\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    #output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "    output = tf.matmul(attention_weights, tf.cast(v, tf.float32))\n",
        "\n",
        "    return output, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "c2a7902c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2a7902c",
        "outputId": "9e27860c-5abb-479d-b955-00cd8c211ecd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([4, 128]), TensorShape([4, 4]))"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = tf.random.uniform((4,128), dtype=tf.int64, minval=0, maxval=200)\n",
        "key = tf.random.uniform((4,128), dtype=tf.int64, minval=0, maxval=200)\n",
        "value = tf.random.uniform((4,128), dtype=tf.int64, minval=0, maxval=200)\n",
        "mask = tf.random.uniform((4, 4), dtype=tf.int64, minval=0, maxval=200)\n",
        "fn_out, fn_w = scaled_dot_product_attention(query, key, value, attention_mask=mask)\n",
        "fn_out.shape, fn_w.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "7c9ed4e5",
      "metadata": {
        "id": "7c9ed4e5"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, name=None):\n",
        "        super(MultiHeadAttention, self).__init__(name=name)\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        # Propagate the mask through this layer\n",
        "        return mask\n",
        "\n",
        "    def call(self, v, k, q, attention_mask=None):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, attention_mask=attention_mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "638c5b29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "638c5b29",
        "outputId": "122b5711-0250-4408-918a-d85a1c877e3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn = temp_mha(y, k=y, q=y, attention_mask=None)  # me - changed from mask to attention_mask\n",
        "out.shape, attn.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd035b14",
      "metadata": {
        "id": "bd035b14"
      },
      "source": [
        "**Masking**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee34ad16",
      "metadata": {
        "id": "ee34ad16"
      },
      "source": [
        "`create_padding_mask`: Prevents attention to padding tokens so only the actual words fromd sonnet are trained on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "0221dab7",
      "metadata": {
        "id": "0221dab7"
      },
      "outputs": [],
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "    # add extra dimensions to add the padding\n",
        "    # to the attention logits.\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "d1e13cdd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1e13cdd",
        "outputId": "729fb1bf-5894-473e-95e8-41ae5ebf36a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c62180bf",
      "metadata": {
        "id": "c62180bf"
      },
      "source": [
        "#### Positional encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oApDW1HFFBk7",
      "metadata": {
        "id": "oApDW1HFFBk7"
      },
      "source": [
        "- Helps the model understand the positioning of words in the sequence\n",
        "- we have used sinusoidal positional encoding for its ability to handle different sequence lengths from our ngram dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "1e67f925",
      "metadata": {
        "id": "1e67f925"
      },
      "outputs": [],
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35c2d2a6",
      "metadata": {
        "id": "35c2d2a6"
      },
      "source": [
        "#### Dense Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "b1207670",
      "metadata": {
        "id": "b1207670"
      },
      "outputs": [],
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "312b927f",
      "metadata": {
        "id": "312b927f"
      },
      "source": [
        "#### Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "307ab74b",
      "metadata": {
        "id": "307ab74b"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training=True, mask=None):\n",
        "        attn_output, _ = self.mha(x, x, x, attention_mask=mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        # Propagate the mask through this layer\n",
        "        return mask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aTC_BKnVHsRD",
      "metadata": {
        "id": "aTC_BKnVHsRD"
      },
      "source": [
        "We create samples to test the class calling and functioning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "76532839",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76532839",
        "outputId": "6d3ba8a4-b03e-4f32-a88f-be701ecc6f7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([64, 43, 512])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 43, 512)), training=False, mask=None)\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "62090874",
      "metadata": {
        "id": "62090874"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                                self.d_model)\n",
        "\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                           for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training=True, mask=None):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        # adding embedding and position encoding.\n",
        "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training=training, mask=mask)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        # Propagate the mask through this layer\n",
        "        return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "4605ff02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4605ff02",
        "outputId": "b3e24dbc-7d2a-4b75-dadf-c2db46219b34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 20, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
        "                         dff=2048, input_vocab_size=8500,\n",
        "                         maximum_position_encoding=10000)\n",
        "temp_input = tf.random.uniform((64, 20), dtype=tf.int64, minval=0, maxval=200)\n",
        "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
        "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6343d2a5",
      "metadata": {
        "id": "6343d2a5"
      },
      "source": [
        "#### Decoder layer and Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "a80779a4",
      "metadata": {
        "id": "a80779a4"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "\n",
        "    def call(self, x, enc_output, training=False, look_ahead_mask=None, padding_mask=None):\n",
        "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, attention_mask=look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(\n",
        "            enc_output, enc_output, out1, attention_mask=padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        # Propagate the mask through this layer\n",
        "        return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "5d65ef32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d65ef32",
        "outputId": "1829526e-9258-4e11-8914-495374aa38b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([64, 20, 512])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    tf.random.uniform((64, 20, 512)), sample_encoder_layer_output,\n",
        "    training=True, look_ahead_mask=None, padding_mask=None)\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "46ae149a",
      "metadata": {
        "id": "46ae149a"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                           for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training=False,\n",
        "           look_ahead_mask=None, padding_mask=None):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training=training,\n",
        "                                                 look_ahead_mask=look_ahead_mask, padding_mask=padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        # x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        # Propagate the mask through this layer\n",
        "        return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "2a141d0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a141d0a",
        "outputId": "0c93e025-3992-4b8a-8a9a-129e3819b247"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([64, 20, 512]), TensorShape([64, 8, 20, 20]))"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
        "                         dff=2048, target_vocab_size=8000,\n",
        "                         maximum_position_encoding=5000)\n",
        "temp_input = tf.random.uniform((64, 20), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "output, attn = sample_decoder(temp_input,\n",
        "                              enc_output=sample_encoder_output,\n",
        "                              training=False,\n",
        "                              look_ahead_mask=None,\n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1ff802a",
      "metadata": {
        "id": "b1ff802a"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YXmVXNHJH_IO",
      "metadata": {
        "id": "YXmVXNHJH_IO"
      },
      "source": [
        "- Encoder + Decoder + Final projection layer\n",
        "\n",
        "In the transformer, we pass the input sequence from the dataset, encoder encodes it to its representation, which is then given to the decoder and it gives a contextualized output (with the help of self attention heads in both encoder and decoder and cross-attention in the decoder). The decoder output is then passed through a dense layer which gives the logits for each vocabulary word (we take the highest probable one)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "ade952d6",
      "metadata": {
        "id": "ade952d6"
      },
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                               input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                               target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inp, tar, training=False, enc_padding_mask=None,\n",
        "           look_ahead_mask=None, dec_padding_mask=None):\n",
        "\n",
        "        enc_output = self.encoder(inp, training=training, mask=enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar, enc_output, training=training, look_ahead_mask=look_ahead_mask, padding_mask=dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "        return final_output, attention_weights\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        # Propagate the mask through this layer\n",
        "        return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "a6e33c3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6e33c3b",
        "outputId": "8dcf8d65-60d7-45ea-c2b1-27b374e5551f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([64, 20, 8000])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_transformer = Transformer(\n",
        "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
        "    input_vocab_size=8500, target_vocab_size=8000,\n",
        "    pe_input=10000, pe_target=6000)\n",
        "\n",
        "temp_input = tf.random.uniform((64, 20), dtype=tf.int32, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((64, 20), dtype=tf.int32, minval=0, maxval=200)\n",
        "\n",
        "fn_out, _ = sample_transformer(temp_input, temp_target, training=False,\n",
        "                               enc_padding_mask=None,\n",
        "                               look_ahead_mask=None,\n",
        "                               dec_padding_mask=None)\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q03aRucaJ3aU",
      "metadata": {
        "id": "Q03aRucaJ3aU"
      },
      "source": [
        "#### Loss function\n",
        "\n",
        "Uses Sparse Categorical Crossentropy to\n",
        "\n",
        "- Ignore padding tokens (0) when computing loss\n",
        "- Prevents model from learning to predict padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "1885c3f4",
      "metadata": {
        "id": "1885c3f4"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "znTGdngIKmRV",
      "metadata": {
        "id": "znTGdngIKmRV"
      },
      "source": [
        "Using `CustomScheduleFloat` for better stability since its casts float32 to avoid dtype issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "1d133d9e",
      "metadata": {
        "id": "1d133d9e"
      },
      "outputs": [],
      "source": [
        "class CustomScheduleFloat(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomScheduleFloat, self).__init__()\n",
        "\n",
        "        self.d_model = tf.constant(d_model,dtype=tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"d_model\": self.d_model,\"warmup_steps\":self.warmup_steps}\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.cast(tf.math.rsqrt(tf.cast(step, tf.float32)), tf.float32)\n",
        "        arg2 = tf.cast(tf.cast(step, tf.float32) * (tf.cast(self.warmup_steps, tf.float32)**-1.5), tf.float32)\n",
        "\n",
        "        size = tf.cast(tf.math.rsqrt(self.d_model), tf.float32)\n",
        "        return tf.math.multiply(size, tf.math.minimum(arg1, arg2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "d9ed68e0",
      "metadata": {
        "id": "d9ed68e0"
      },
      "outputs": [],
      "source": [
        "sample_learning_rate = CustomScheduleFloat(d_model=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "91009ba8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "91009ba8",
        "outputId": "47e83e83-404a-4a6a-be56-2700acaba6b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z4MIzlnpK5OR",
      "metadata": {
        "id": "Z4MIzlnpK5OR"
      },
      "source": [
        "- `create_look_ahead_mask`:Prevents decoder from seeing future tokens during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "a1760124",
      "metadata": {
        "id": "a1760124"
      },
      "outputs": [],
      "source": [
        "def create_look_ahead_mask(x):\n",
        "    # Extract the sequence length dynamically from the tensor x\n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # Create the matrix (seq_len, seq_len)\n",
        "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "\n",
        "    return look_ahead_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BwzgUohuLKBI",
      "metadata": {
        "id": "BwzgUohuLKBI"
      },
      "source": [
        "- `enc_padding_mask`: For encoder self-attention\n",
        "    - Prevents attention to padding in input sequence\n",
        "\n",
        "- `combined_mask`: For decoder self-attention\n",
        "    - Combination of look-ahead mask + padding mask\n",
        "    - Prevents seeing future tokens and attention to padding\n",
        "\n",
        "- `dec_padding_mask`: For decoder cross-attention to encoder\n",
        "    - Prevents decoder from attention to padding in encoder output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "aabd00c2",
      "metadata": {
        "id": "aabd00c2"
      },
      "outputs": [],
      "source": [
        "def create_masks(inp, tar):\n",
        "    # Encoder padding mask\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 2nd attention block in the decoder.\n",
        "    # This padding mask is used to mask the encoder outputs.\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 1st attention block in the decoder.\n",
        "    # It is used to pad and mask future tokens in the input received by\n",
        "    # the decoder.\n",
        "    #look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    look_ahead_mask = create_look_ahead_mask(tar)\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "764ef0d3",
      "metadata": {
        "id": "764ef0d3"
      },
      "source": [
        "### Create and Train the Model\n",
        "\n",
        "We use the hyper parameters below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "8EhTUwncCQo4",
      "metadata": {
        "id": "8EhTUwncCQo4"
      },
      "outputs": [],
      "source": [
        "# Maximum sentence length\n",
        "MAX_LENGTH = 20\n",
        "\n",
        "# For Transformer\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 512\n",
        "NUM_HEADS = 8\n",
        "UNITS = 2048\n",
        "DROPOUT = 0.15\n",
        "\n",
        "EPOCHS = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "2eec5760",
      "metadata": {
        "id": "2eec5760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\yohan\\anaconda3\\envs\\info6106\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "learning_rate = CustomScheduleFloat(d_model=D_MODEL)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "transformer = Transformer(num_layers=NUM_LAYERS, d_model=D_MODEL, num_heads=NUM_HEADS, dff=UNITS,\n",
        "                          input_vocab_size=VOCAB_SIZE, target_vocab_size=VOCAB_SIZE,\n",
        "                          pe_input=VOCAB_SIZE,\n",
        "                          pe_target=VOCAB_SIZE,\n",
        "                          rate=DROPOUT)\n",
        "\n",
        "transformer.compile(optimizer=optimizer, loss=loss_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "46243a11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46243a11",
        "outputId": "87f4cd30-fe81-45b3-85c5-dcf131ff8952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint directory already exists: ./data/training_checkpoints/transformer\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "checkpoint_path = \"./data/training_checkpoints/transformer\"\n",
        "\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    os.makedirs(checkpoint_path)\n",
        "    print(f\"Created checkpoint directory: {checkpoint_path}\")\n",
        "else:\n",
        "    print(f\"Checkpoint directory already exists: {checkpoint_path}\")\n",
        "\n",
        "# Links the checkpoint to your specific model and optimizer\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "# 4. Create the CheckpointManager\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# # 5. Restore the latest checkpoint if it exists\n",
        "# if ckpt_manager.latest_checkpoint:\n",
        "#     ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "#     print('Latest checkpoint restored!!')\n",
        "# else:\n",
        "#     print('No checkpoint found. Initializing from scratch.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "e198e88c",
      "metadata": {
        "id": "e198e88c"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5323f5a2",
      "metadata": {
        "id": "5323f5a2"
      },
      "outputs": [],
      "source": [
        "\n",
        "@tf.function\n",
        "def train_step(inp, dec_inp, tar):\n",
        "    \"\"\"\n",
        "    inp: encoder input\n",
        "    dec_inp: decoder input (already has START_TOKEN prepended, last token removed)\n",
        "    tar: target outputs (labels for loss calculation)\n",
        "    \"\"\"\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(dec_inp)\n",
        "    dec_target_padding_mask = create_padding_mask(dec_inp)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp,\n",
        "            dec_inp,\n",
        "            training=True,\n",
        "            enc_padding_mask=enc_padding_mask,\n",
        "            look_ahead_mask=combined_mask,\n",
        "            dec_padding_mask=dec_padding_mask\n",
        "        )\n",
        "\n",
        "        # Calculate loss against tar (full target sequence)\n",
        "        loss = loss_function(tar, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(tar, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yybGhXPMt0nb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yybGhXPMt0nb",
        "outputId": "b274916f-75ea-401e-97f5-16de301fcdbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 8.3717 Accuracy 0.0000\n",
            "Epoch 1 Batch 200 Loss 7.3641 Accuracy 0.0014\n",
            "Epoch 1 Batch 400 Loss 6.6356 Accuracy 0.0098\n",
            "Epoch 1 Batch 600 Loss 5.8688 Accuracy 0.0332\n",
            "Epoch 1 Batch 800 Loss 5.0072 Accuracy 0.0774\n",
            "Epoch 1 Loss 4.5913 Accuracy 0.0986\n",
            "Epoch 2 Batch 0 Loss 4.5908 Accuracy 0.0985\n",
            "Epoch 2 Batch 200 Loss 4.5705 Accuracy 0.0831\n",
            "Epoch 2 Batch 400 Loss 4.2401 Accuracy 0.0801\n",
            "Epoch 2 Batch 600 Loss 3.8103 Accuracy 0.0948\n",
            "Epoch 2 Batch 800 Loss 3.4297 Accuracy 0.1188\n",
            "Epoch 2 Loss 3.2550 Accuracy 0.1296\n",
            "Epoch 3 Batch 0 Loss 3.2552 Accuracy 0.1296\n",
            "Epoch 3 Batch 200 Loss 3.2780 Accuracy 0.1185\n",
            "Epoch 3 Batch 400 Loss 3.1242 Accuracy 0.1145\n",
            "Epoch 3 Batch 600 Loss 2.9214 Accuracy 0.1213\n",
            "Epoch 3 Batch 800 Loss 2.7309 Accuracy 0.1355\n",
            "Epoch 3 Loss 2.6414 Accuracy 0.1418\n",
            "Epoch 4 Batch 0 Loss 2.6419 Accuracy 0.1418\n",
            "Epoch 4 Batch 200 Loss 2.7109 Accuracy 0.1332\n",
            "Epoch 4 Batch 400 Loss 2.6421 Accuracy 0.1293\n",
            "Epoch 4 Batch 600 Loss 2.5336 Accuracy 0.1328\n",
            "Epoch 4 Batch 800 Loss 2.4255 Accuracy 0.1414\n",
            "Epoch 4 Loss 2.3716 Accuracy 0.1458\n",
            "Epoch 5 Batch 0 Loss 2.3719 Accuracy 0.1457\n",
            "Epoch 5 Batch 200 Loss 2.4500 Accuracy 0.1390\n",
            "Epoch 5 Batch 400 Loss 2.4164 Accuracy 0.1354\n",
            "Epoch 5 Batch 600 Loss 2.3510 Accuracy 0.1372\n",
            "Epoch 5 Batch 800 Loss 2.2831 Accuracy 0.1431\n",
            "Saving checkpoint for epoch 5 at ./data/training_checkpoints/transformer/ckpt-1\n",
            "Epoch 5 Loss 2.2453 Accuracy 0.1463\n",
            "Epoch 6 Batch 0 Loss 2.2459 Accuracy 0.1463\n",
            "Epoch 6 Batch 200 Loss 2.2983 Accuracy 0.1409\n",
            "Epoch 6 Batch 400 Loss 2.2624 Accuracy 0.1382\n",
            "Epoch 6 Batch 600 Loss 2.2038 Accuracy 0.1401\n",
            "Epoch 6 Batch 800 Loss 2.1449 Accuracy 0.1453\n",
            "Epoch 6 Loss 2.1129 Accuracy 0.1483\n",
            "Epoch 7 Batch 0 Loss 2.1131 Accuracy 0.1483\n",
            "Epoch 7 Batch 200 Loss 2.1435 Accuracy 0.1438\n",
            "Epoch 7 Batch 400 Loss 2.1087 Accuracy 0.1415\n",
            "Epoch 7 Batch 600 Loss 2.0578 Accuracy 0.1434\n",
            "Epoch 7 Batch 800 Loss 2.0076 Accuracy 0.1481\n",
            "Epoch 7 Loss 1.9808 Accuracy 0.1507\n",
            "Epoch 8 Batch 0 Loss 1.9809 Accuracy 0.1506\n",
            "Epoch 8 Batch 200 Loss 2.0003 Accuracy 0.1468\n",
            "Epoch 8 Batch 400 Loss 1.9683 Accuracy 0.1449\n",
            "Epoch 8 Batch 600 Loss 1.9240 Accuracy 0.1466\n",
            "Epoch 8 Batch 800 Loss 1.8809 Accuracy 0.1509\n",
            "Epoch 8 Loss 1.8583 Accuracy 0.1532\n",
            "Epoch 9 Batch 0 Loss 1.8583 Accuracy 0.1532\n",
            "Epoch 9 Batch 200 Loss 1.8688 Accuracy 0.1497\n",
            "Epoch 9 Batch 400 Loss 1.8404 Accuracy 0.1481\n",
            "Epoch 9 Batch 600 Loss 1.8024 Accuracy 0.1496\n",
            "Epoch 9 Batch 800 Loss 1.7653 Accuracy 0.1536\n",
            "Epoch 9 Loss 1.7457 Accuracy 0.1556\n",
            "Epoch 10 Batch 0 Loss 1.7458 Accuracy 0.1556\n",
            "Epoch 10 Batch 200 Loss 1.7538 Accuracy 0.1525\n",
            "Epoch 10 Batch 400 Loss 1.7281 Accuracy 0.1511\n",
            "Epoch 10 Batch 600 Loss 1.6952 Accuracy 0.1524\n",
            "Epoch 10 Batch 800 Loss 1.6632 Accuracy 0.1560\n",
            "Saving checkpoint for epoch 10 at ./data/training_checkpoints/transformer/ckpt-2\n",
            "Epoch 10 Loss 1.6465 Accuracy 0.1579\n",
            "Epoch 11 Batch 0 Loss 1.6464 Accuracy 0.1579\n",
            "Epoch 11 Batch 200 Loss 1.6503 Accuracy 0.1551\n",
            "Epoch 11 Batch 400 Loss 1.6279 Accuracy 0.1537\n",
            "Epoch 11 Batch 600 Loss 1.5994 Accuracy 0.1550\n",
            "Epoch 11 Batch 800 Loss 1.5715 Accuracy 0.1582\n",
            "Epoch 11 Loss 1.5569 Accuracy 0.1599\n",
            "Epoch 12 Batch 0 Loss 1.5569 Accuracy 0.1599\n",
            "Epoch 12 Batch 200 Loss 1.5595 Accuracy 0.1574\n",
            "Epoch 12 Batch 400 Loss 1.5396 Accuracy 0.1561\n",
            "Epoch 12 Batch 600 Loss 1.5145 Accuracy 0.1572\n",
            "Epoch 12 Batch 800 Loss 1.4900 Accuracy 0.1602\n",
            "Epoch 12 Loss 1.4771 Accuracy 0.1617\n",
            "Epoch 13 Batch 0 Loss 1.4772 Accuracy 0.1617\n",
            "Epoch 13 Batch 200 Loss 1.4776 Accuracy 0.1594\n",
            "Epoch 13 Batch 400 Loss 1.4600 Accuracy 0.1582\n",
            "Epoch 13 Batch 600 Loss 1.4381 Accuracy 0.1592\n",
            "Epoch 13 Batch 800 Loss 1.4163 Accuracy 0.1621\n",
            "Epoch 13 Loss 1.4050 Accuracy 0.1634\n",
            "Epoch 14 Batch 0 Loss 1.4049 Accuracy 0.1634\n",
            "Epoch 14 Batch 200 Loss 1.4050 Accuracy 0.1612\n",
            "Epoch 14 Batch 400 Loss 1.3894 Accuracy 0.1601\n",
            "Epoch 14 Batch 600 Loss 1.3698 Accuracy 0.1611\n",
            "Epoch 14 Batch 800 Loss 1.3504 Accuracy 0.1636\n",
            "Epoch 14 Loss 1.3403 Accuracy 0.1649\n",
            "Epoch 15 Batch 0 Loss 1.3403 Accuracy 0.1649\n",
            "Epoch 15 Batch 200 Loss 1.3403 Accuracy 0.1629\n",
            "Epoch 15 Batch 400 Loss 1.3263 Accuracy 0.1618\n",
            "Epoch 15 Batch 600 Loss 1.3086 Accuracy 0.1627\n",
            "Epoch 15 Batch 800 Loss 1.2912 Accuracy 0.1651\n",
            "Saving checkpoint for epoch 15 at ./data/training_checkpoints/transformer/ckpt-3\n",
            "Epoch 15 Loss 1.2822 Accuracy 0.1663\n",
            "Epoch 16 Batch 0 Loss 1.2822 Accuracy 0.1663\n",
            "Epoch 16 Batch 200 Loss 1.2819 Accuracy 0.1644\n",
            "Epoch 16 Batch 400 Loss 1.2691 Accuracy 0.1634\n",
            "Epoch 16 Batch 600 Loss 1.2533 Accuracy 0.1642\n",
            "Epoch 16 Batch 800 Loss 1.2377 Accuracy 0.1664\n",
            "Epoch 16 Loss 1.2295 Accuracy 0.1675\n",
            "Epoch 17 Batch 0 Loss 1.2295 Accuracy 0.1675\n",
            "Epoch 17 Batch 200 Loss 1.2288 Accuracy 0.1657\n",
            "Epoch 17 Batch 400 Loss 1.2173 Accuracy 0.1648\n",
            "Epoch 17 Batch 600 Loss 1.2029 Accuracy 0.1655\n",
            "Epoch 17 Batch 800 Loss 1.1887 Accuracy 0.1676\n",
            "Epoch 17 Loss 1.1813 Accuracy 0.1687\n",
            "Epoch 18 Batch 0 Loss 1.1813 Accuracy 0.1687\n",
            "Epoch 18 Batch 200 Loss 1.1805 Accuracy 0.1670\n",
            "Epoch 18 Batch 400 Loss 1.1699 Accuracy 0.1661\n",
            "Epoch 18 Batch 600 Loss 1.1567 Accuracy 0.1668\n",
            "Epoch 18 Batch 800 Loss 1.1438 Accuracy 0.1687\n",
            "Epoch 18 Loss 1.1370 Accuracy 0.1697\n",
            "Epoch 19 Batch 0 Loss 1.1370 Accuracy 0.1697\n",
            "Epoch 19 Batch 200 Loss 1.1362 Accuracy 0.1681\n",
            "Epoch 19 Batch 400 Loss 1.1264 Accuracy 0.1672\n",
            "Epoch 19 Batch 600 Loss 1.1145 Accuracy 0.1679\n",
            "Epoch 19 Batch 800 Loss 1.1026 Accuracy 0.1697\n",
            "Epoch 19 Loss 1.0965 Accuracy 0.1707\n",
            "Epoch 20 Batch 0 Loss 1.0965 Accuracy 0.1707\n",
            "Epoch 20 Batch 200 Loss 1.0962 Accuracy 0.1691\n",
            "Epoch 20 Batch 400 Loss 1.0874 Accuracy 0.1683\n",
            "Epoch 20 Batch 600 Loss 1.0764 Accuracy 0.1689\n",
            "Epoch 20 Batch 800 Loss 1.0655 Accuracy 0.1707\n",
            "Saving checkpoint for epoch 20 at ./data/training_checkpoints/transformer/ckpt-4\n",
            "Epoch 20 Loss 1.0598 Accuracy 0.1716\n",
            "Epoch 21 Batch 0 Loss 1.0598 Accuracy 0.1716\n",
            "Epoch 21 Batch 200 Loss 1.0597 Accuracy 0.1701\n",
            "Epoch 21 Batch 400 Loss 1.0514 Accuracy 0.1693\n",
            "Epoch 21 Batch 600 Loss 1.0414 Accuracy 0.1699\n",
            "Epoch 21 Batch 800 Loss 1.0313 Accuracy 0.1715\n",
            "Epoch 21 Loss 1.0260 Accuracy 0.1724\n",
            "Epoch 22 Batch 0 Loss 1.0260 Accuracy 0.1724\n",
            "Epoch 22 Batch 200 Loss 1.0254 Accuracy 0.1710\n",
            "Epoch 22 Batch 400 Loss 1.0178 Accuracy 0.1702\n",
            "Epoch 22 Batch 600 Loss 1.0084 Accuracy 0.1708\n",
            "Epoch 22 Batch 800 Loss 0.9990 Accuracy 0.1724\n",
            "Epoch 22 Loss 0.9942 Accuracy 0.1732\n",
            "Epoch 23 Batch 0 Loss 0.9942 Accuracy 0.1732\n",
            "Epoch 23 Batch 200 Loss 0.9941 Accuracy 0.1718\n",
            "Epoch 23 Batch 400 Loss 0.9870 Accuracy 0.1711\n",
            "Epoch 23 Batch 600 Loss 0.9783 Accuracy 0.1716\n",
            "Epoch 23 Batch 800 Loss 0.9696 Accuracy 0.1731\n",
            "Epoch 23 Loss 0.9651 Accuracy 0.1739\n",
            "Epoch 24 Batch 0 Loss 0.9651 Accuracy 0.1739\n",
            "Epoch 24 Batch 200 Loss 0.9646 Accuracy 0.1726\n",
            "Epoch 24 Batch 400 Loss 0.9581 Accuracy 0.1719\n",
            "Epoch 24 Batch 600 Loss 0.9500 Accuracy 0.1724\n",
            "Epoch 24 Batch 800 Loss 0.9418 Accuracy 0.1738\n",
            "Epoch 24 Loss 0.9376 Accuracy 0.1745\n",
            "Epoch 25 Batch 0 Loss 0.9376 Accuracy 0.1745\n",
            "Epoch 25 Batch 200 Loss 0.9375 Accuracy 0.1733\n",
            "Epoch 25 Batch 400 Loss 0.9313 Accuracy 0.1726\n",
            "Epoch 25 Batch 600 Loss 0.9237 Accuracy 0.1731\n",
            "Epoch 25 Batch 800 Loss 0.9161 Accuracy 0.1744\n",
            "Saving checkpoint for epoch 25 at ./data/training_checkpoints/transformer/ckpt-5\n",
            "Epoch 25 Loss 0.9121 Accuracy 0.1752\n",
            "Epoch 26 Batch 0 Loss 0.9121 Accuracy 0.1752\n",
            "Epoch 26 Batch 200 Loss 0.9121 Accuracy 0.1740\n",
            "Epoch 26 Batch 400 Loss 0.9064 Accuracy 0.1733\n",
            "Epoch 26 Batch 600 Loss 0.8994 Accuracy 0.1738\n",
            "Epoch 26 Batch 800 Loss 0.8922 Accuracy 0.1751\n",
            "Epoch 26 Loss 0.8885 Accuracy 0.1758\n",
            "Epoch 27 Batch 0 Loss 0.8885 Accuracy 0.1757\n",
            "Epoch 27 Batch 200 Loss 0.8885 Accuracy 0.1746\n",
            "Epoch 27 Batch 400 Loss 0.8832 Accuracy 0.1740\n",
            "Epoch 27 Batch 600 Loss 0.8765 Accuracy 0.1744\n",
            "Epoch 27 Batch 800 Loss 0.8698 Accuracy 0.1757\n",
            "Epoch 27 Loss 0.8663 Accuracy 0.1763\n",
            "Epoch 28 Batch 0 Loss 0.8663 Accuracy 0.1763\n",
            "Epoch 28 Batch 200 Loss 0.8662 Accuracy 0.1752\n",
            "Epoch 28 Batch 400 Loss 0.8611 Accuracy 0.1746\n",
            "Epoch 28 Batch 600 Loss 0.8549 Accuracy 0.1750\n",
            "Epoch 28 Batch 800 Loss 0.8486 Accuracy 0.1762\n",
            "Epoch 28 Loss 0.8453 Accuracy 0.1768\n",
            "Epoch 29 Batch 0 Loss 0.8453 Accuracy 0.1768\n",
            "Epoch 29 Batch 200 Loss 0.8452 Accuracy 0.1757\n",
            "Epoch 29 Batch 400 Loss 0.8406 Accuracy 0.1751\n",
            "Epoch 29 Batch 600 Loss 0.8347 Accuracy 0.1755\n",
            "Epoch 29 Batch 800 Loss 0.8288 Accuracy 0.1767\n",
            "Epoch 29 Loss 0.8257 Accuracy 0.1773\n",
            "Epoch 30 Batch 0 Loss 0.8257 Accuracy 0.1773\n",
            "Epoch 30 Batch 200 Loss 0.8258 Accuracy 0.1762\n",
            "Epoch 30 Batch 400 Loss 0.8214 Accuracy 0.1757\n",
            "Epoch 30 Batch 600 Loss 0.8158 Accuracy 0.1760\n",
            "Epoch 30 Batch 800 Loss 0.8102 Accuracy 0.1772\n",
            "Saving checkpoint for epoch 30 at ./data/training_checkpoints/transformer/ckpt-6\n",
            "Epoch 30 Loss 0.8072 Accuracy 0.1777\n",
            "Epoch 31 Batch 0 Loss 0.8073 Accuracy 0.1777\n",
            "Epoch 31 Batch 200 Loss 0.8072 Accuracy 0.1767\n",
            "Epoch 31 Batch 400 Loss 0.8029 Accuracy 0.1762\n",
            "Epoch 31 Batch 600 Loss 0.7976 Accuracy 0.1765\n",
            "Epoch 31 Batch 800 Loss 0.7923 Accuracy 0.1776\n",
            "Epoch 31 Loss 0.7896 Accuracy 0.1782\n",
            "Epoch 32 Batch 0 Loss 0.7896 Accuracy 0.1782\n",
            "Epoch 32 Batch 200 Loss 0.7896 Accuracy 0.1772\n",
            "Epoch 32 Batch 400 Loss 0.7856 Accuracy 0.1767\n",
            "Epoch 32 Batch 600 Loss 0.7806 Accuracy 0.1770\n",
            "Epoch 32 Batch 800 Loss 0.7756 Accuracy 0.1780\n",
            "Epoch 32 Loss 0.7729 Accuracy 0.1786\n",
            "Epoch 33 Batch 0 Loss 0.7729 Accuracy 0.1786\n",
            "Epoch 33 Batch 200 Loss 0.7731 Accuracy 0.1776\n",
            "Epoch 33 Batch 400 Loss 0.7693 Accuracy 0.1771\n",
            "Epoch 33 Batch 600 Loss 0.7646 Accuracy 0.1774\n",
            "Epoch 33 Batch 800 Loss 0.7598 Accuracy 0.1784\n",
            "Epoch 33 Loss 0.7573 Accuracy 0.1790\n",
            "Epoch 34 Batch 0 Loss 0.7573 Accuracy 0.1790\n",
            "Epoch 34 Batch 200 Loss 0.7574 Accuracy 0.1780\n",
            "Epoch 34 Batch 400 Loss 0.7538 Accuracy 0.1775\n",
            "Epoch 34 Batch 600 Loss 0.7493 Accuracy 0.1778\n",
            "Epoch 34 Batch 800 Loss 0.7447 Accuracy 0.1788\n",
            "Epoch 34 Loss 0.7423 Accuracy 0.1793\n",
            "Epoch 35 Batch 0 Loss 0.7423 Accuracy 0.1793\n",
            "Epoch 35 Batch 200 Loss 0.7425 Accuracy 0.1784\n",
            "Epoch 35 Batch 400 Loss 0.7392 Accuracy 0.1779\n",
            "Epoch 35 Batch 600 Loss 0.7349 Accuracy 0.1782\n",
            "Epoch 35 Batch 800 Loss 0.7305 Accuracy 0.1792\n",
            "Saving checkpoint for epoch 35 at ./data/training_checkpoints/transformer/ckpt-7\n",
            "Epoch 35 Loss 0.7282 Accuracy 0.1797\n",
            "Epoch 36 Batch 0 Loss 0.7282 Accuracy 0.1797\n",
            "Epoch 36 Batch 200 Loss 0.7286 Accuracy 0.1788\n",
            "Epoch 36 Batch 400 Loss 0.7253 Accuracy 0.1783\n",
            "Epoch 36 Batch 600 Loss 0.7212 Accuracy 0.1786\n",
            "Epoch 36 Batch 800 Loss 0.7170 Accuracy 0.1795\n",
            "Epoch 36 Loss 0.7149 Accuracy 0.1800\n",
            "Epoch 37 Batch 0 Loss 0.7149 Accuracy 0.1800\n",
            "Epoch 37 Batch 200 Loss 0.7151 Accuracy 0.1791\n",
            "Epoch 37 Batch 400 Loss 0.7121 Accuracy 0.1787\n",
            "Epoch 37 Batch 600 Loss 0.7081 Accuracy 0.1790\n",
            "Epoch 37 Batch 800 Loss 0.7042 Accuracy 0.1799\n",
            "Epoch 37 Loss 0.7021 Accuracy 0.1803\n",
            "Epoch 38 Batch 0 Loss 0.7021 Accuracy 0.1803\n",
            "Epoch 38 Batch 200 Loss 0.7023 Accuracy 0.1795\n",
            "Epoch 38 Batch 400 Loss 0.6994 Accuracy 0.1790\n",
            "Epoch 38 Batch 600 Loss 0.6957 Accuracy 0.1793\n",
            "Epoch 38 Batch 800 Loss 0.6919 Accuracy 0.1802\n",
            "Epoch 38 Loss 0.6899 Accuracy 0.1806\n",
            "Epoch 39 Batch 0 Loss 0.6899 Accuracy 0.1806\n",
            "Epoch 39 Batch 200 Loss 0.6901 Accuracy 0.1798\n",
            "Epoch 39 Batch 400 Loss 0.6873 Accuracy 0.1793\n",
            "Epoch 39 Batch 600 Loss 0.6837 Accuracy 0.1796\n",
            "Epoch 39 Batch 800 Loss 0.6801 Accuracy 0.1805\n",
            "Epoch 39 Loss 0.6782 Accuracy 0.1809\n",
            "Epoch 40 Batch 0 Loss 0.6782 Accuracy 0.1809\n",
            "Epoch 40 Batch 200 Loss 0.6784 Accuracy 0.1801\n",
            "Epoch 40 Batch 400 Loss 0.6758 Accuracy 0.1797\n",
            "Epoch 40 Batch 600 Loss 0.6724 Accuracy 0.1799\n",
            "Epoch 40 Batch 800 Loss 0.6689 Accuracy 0.1807\n",
            "Saving checkpoint for epoch 40 at ./data/training_checkpoints/transformer/ckpt-8\n",
            "Epoch 40 Loss 0.6670 Accuracy 0.1812\n"
          ]
        }
      ],
      "source": [
        "# The actual training loop\n",
        "EPOCHS = 40  # Set your desired epochs\n",
        "for epoch in range(EPOCHS):\n",
        "    for (batch, (inp_dict, tar_dict)) in enumerate(dataset):\n",
        "        source = inp_dict['inputs']\n",
        "        dec_input = inp_dict['dec_inputs']\n",
        "        target = tar_dict['outputs']\n",
        "\n",
        "        train_step(source, dec_input, target)  # Pass all three\n",
        "\n",
        "        if batch % 200 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "                epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "\n",
        "    # Save checkpoint every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "\n",
        "    print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "        epoch + 1, train_loss.result(), train_accuracy.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c1946e0",
      "metadata": {},
      "source": [
        "With 40 epochs, We got the loss down to 0.66 and the accuracy up to 18%. The accuracy did not increased steadly from 1-20 epochs (16%), however, after that it started to plateau and learning did not improve much after 18%"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J3H8nm2PPB--",
      "metadata": {
        "id": "J3H8nm2PPB--"
      },
      "source": [
        "**Save model weights and Info**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "YxUctW3lKsbn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxUctW3lKsbn",
        "outputId": "648dbc9f-05a5-495f-81bf-4182a0d46e05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Weights saved\n"
          ]
        }
      ],
      "source": [
        "transformer.save_weights('data/shakespeare_weights.weights.h5')\n",
        "print(\"✅ Weights saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "WfBxsAP1KwZt",
      "metadata": {
        "id": "WfBxsAP1KwZt"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "model_data = {\n",
        "    'tokenizer': tokenizer,\n",
        "    'START_TOKEN': START_TOKEN,\n",
        "    'END_TOKEN': END_TOKEN,\n",
        "    'VOCAB_SIZE': VOCAB_SIZE,\n",
        "    'MAX_LENGTH': MAX_LENGTH,\n",
        "    'NUM_LAYERS': NUM_LAYERS,\n",
        "    'D_MODEL': D_MODEL,\n",
        "    'NUM_HEADS': NUM_HEADS,\n",
        "    'UNITS': UNITS,\n",
        "    'DROPOUT': DROPOUT\n",
        "}\n",
        "\n",
        "with open('data/model_data.pkl', 'wb') as f:\n",
        "    pickle.dump(model_data, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mudx8K0ePHEg",
      "metadata": {
        "id": "Mudx8K0ePHEg"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "g-ox5LrYPKNE",
      "metadata": {
        "id": "g-ox5LrYPKNE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Tokenizer and constants loaded\n",
            "   VOCAB_SIZE: 3291, START: 3289, END: 3290\n",
            "✅ Model architecture created\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Load model_data.pkl\n",
        "with open('data/model_data.pkl', 'rb') as f:\n",
        "    model_data = pickle.load(f)\n",
        "\n",
        "tokenizer = model_data['tokenizer']\n",
        "START_TOKEN = model_data['START_TOKEN']\n",
        "END_TOKEN = model_data['END_TOKEN']\n",
        "VOCAB_SIZE = model_data['VOCAB_SIZE']\n",
        "MAX_LENGTH = model_data['MAX_LENGTH']\n",
        "D_MODEL = model_data['D_MODEL']\n",
        "NUM_HEADS = model_data['NUM_HEADS']\n",
        "DROPOUT = model_data['DROPOUT']\n",
        "\n",
        "print(\"✅ Tokenizer and constants loaded\")\n",
        "print(f\"   VOCAB_SIZE: {VOCAB_SIZE}, START: {START_TOKEN}, END: {END_TOKEN}\")\n",
        "\n",
        "# Recreate the EXACT model architecture\n",
        "transformer = Transformer(num_layers=NUM_LAYERS, d_model=D_MODEL, num_heads=NUM_HEADS, dff=UNITS,\n",
        "                          input_vocab_size=VOCAB_SIZE, target_vocab_size=VOCAB_SIZE,\n",
        "                          pe_input=VOCAB_SIZE,\n",
        "                          pe_target=VOCAB_SIZE,\n",
        "                          rate=DROPOUT)\n",
        "\n",
        "# Build model with dummy forward pass\n",
        "dummy_inp = tf.random.uniform((1, 20), dtype=tf.int32, minval=0, maxval=100)\n",
        "dummy_tar = tf.random.uniform((1, 19), dtype=tf.int32, minval=0, maxval=100)\n",
        "_ = transformer(dummy_inp, dummy_tar, training=False)\n",
        "\n",
        "print(\"✅ Model architecture created\")\n",
        "\n",
        "# Load the trained weights\n",
        "transformer.load_weights('data/shakespeare_weights.weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a34837b",
      "metadata": {},
      "source": [
        "### Inference\n",
        "\n",
        "We have used two ways to generate the output id or token from the model.\n",
        "\n",
        "Greedy Sampling: Looks at the predicted probabilities in the vocabulary and always picks the word with highest probability. It gives consistent outputs, but may get stuck in repetitive patterns\n",
        "\n",
        "Temperature Sampling: It adjusts probability distribution with temperature. If its Temperature=1, then the prob distribution remains the same and the words have the associated probability of being picked. If we decrease the temparature it boosts the higher probable word and reduces the other words probability. If we increase it it flattens the distribution to make it more creative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "1c84c8a3",
      "metadata": {
        "id": "1c84c8a3"
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence, temperature=0.8, sampling_method='top_p', top_k=40, top_p=0.9):\n",
        "\n",
        "    # Tokenize the input sentence using the Keras Tokenizer\n",
        "    sentence_tokens = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "    # Add START and END tokens\n",
        "    sentence_input = [START_TOKEN] + sentence_tokens + [END_TOKEN]\n",
        "\n",
        "    # Add batch dimension: (1, seq_len)\n",
        "    sentence_input = tf.expand_dims(sentence_input, 0)\n",
        "\n",
        "    # The decoder input starts with just the START_TOKEN\n",
        "    output = tf.expand_dims([START_TOKEN], 0)\n",
        "\n",
        "    # Loop to generate the next word\n",
        "    for i in range(MAX_LENGTH):\n",
        "        # Create masks\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "            sentence_input, output)\n",
        "\n",
        "        # Forward pass (training=False)\n",
        "        predictions, attention_weights = transformer(\n",
        "            sentence_input,\n",
        "            output,\n",
        "            training=False,\n",
        "            enc_padding_mask=enc_padding_mask,\n",
        "            look_ahead_mask=combined_mask,\n",
        "            dec_padding_mask=dec_padding_mask\n",
        "        )\n",
        "\n",
        "        # Select the last token from the seq_len dimension\n",
        "        predictions = predictions[:, -1, :]  # (batch_size, vocab_size)\n",
        "\n",
        "        # Apply sampling strategy\n",
        "        if sampling_method == 'greedy':\n",
        "            predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        elif sampling_method == 'temperature':\n",
        "            scaled_predictions = predictions / temperature\n",
        "            predicted_id = tf.random.categorical(scaled_predictions, num_samples=1)\n",
        "            predicted_id = tf.cast(predicted_id[0], tf.int32)\n",
        "\n",
        "        # Stop if the END_TOKEN is predicted\n",
        "        if tf.equal(predicted_id, END_TOKEN):\n",
        "            break\n",
        "\n",
        "        # Concatenate the predicted_id to the output\n",
        "        predicted_id = tf.expand_dims(predicted_id, 0)\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "36f3a46d",
      "metadata": {
        "id": "36f3a46d"
      },
      "outputs": [],
      "source": [
        "def predict(sentence, temperature=0.8, sampling_method='top_p', top_k=40, top_p=0.9):\n",
        "    prediction = evaluate(sentence, temperature, sampling_method, top_k, top_p)\n",
        "    predicted_sentence = []\n",
        "\n",
        "    # Iterate through the predicted IDs\n",
        "    for i in prediction.numpy():\n",
        "        i = int(i)\n",
        "        # Skip special tokens (Start, End, and Pad=0)\n",
        "        if i == START_TOKEN or i == END_TOKEN or i == 0:\n",
        "            continue\n",
        "        \n",
        "        word = tokenizer.index_word.get(i)\n",
        "        if word:\n",
        "            predicted_sentence.append(word)\n",
        "\n",
        "    result = \" \".join(predicted_sentence)\n",
        "\n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Sampling: {} (temp={}, k={}, p={})'.format(\n",
        "        sampling_method, temperature, top_k, top_p))\n",
        "    print('Output: {}'.format(result))\n",
        "    print()\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6f70e73",
      "metadata": {},
      "source": [
        "Lets test the inference with both greedy and temperature sampling to generate one line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "054bf6cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "054bf6cb",
        "outputId": "7222e6d5-00cd-4efe-e0d0-f8a24e845eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GREEDY SAMPLING\n",
            "Input: wherefore art thou Romeo\n",
            "Sampling: greedy (temp=0.8, k=40, p=0.9)\n",
            "Output: and dost advance as high as learning\n",
            "\n",
            "TEMPERATURE SAMPLING\n",
            "Input: wherefore art thou Romeo\n",
            "Sampling: temperature (temp=0.8, k=40, p=0.9)\n",
            "Output: and dost him thou art\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'and dost him thou art'"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test different sampling methods\n",
        "test_sentence = \"wherefore art thou Romeo\"\n",
        "\n",
        "print(\"GREEDY SAMPLING\")\n",
        "\n",
        "predict(test_sentence, sampling_method='greedy')\n",
        "\n",
        "print(\"TEMPERATURE SAMPLING\")\n",
        "\n",
        "predict(test_sentence, sampling_method='temperature', temperature=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "8157e3f9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GREEDY SAMPLING\n",
            "Input: wherefore art thou Romeo\n",
            "Sampling: greedy (temp=0.8, k=40, p=0.9)\n",
            "Output: and dost advance as high as learning\n",
            "\n",
            "TEMPERATURE SAMPLING\n",
            "Input: wherefore art thou Romeo\n",
            "Sampling: temperature (temp=1.5, k=40, p=0.9)\n",
            "Output: and therefore art true\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'and therefore art true'"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test different sampling methods\n",
        "test_sentence = \"wherefore art thou Romeo\"\n",
        "\n",
        "print(\"GREEDY SAMPLING\")\n",
        "\n",
        "predict(test_sentence, sampling_method='greedy')\n",
        "\n",
        "print(\"TEMPERATURE SAMPLING\")\n",
        "\n",
        "predict(test_sentence, sampling_method='temperature', temperature=1.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "eb3c5f05",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GREEDY SAMPLING\n",
            "Input: wherefore art thou Romeo\n",
            "Sampling: greedy (temp=0.8, k=40, p=0.9)\n",
            "Output: and dost advance as high as learning\n",
            "\n",
            "TEMPERATURE SAMPLING\n",
            "Input: wherefore art thou Romeo\n",
            "Sampling: temperature (temp=1, k=40, p=0.9)\n",
            "Output: and dost him leave\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'and dost him leave'"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test different sampling methods\n",
        "test_sentence = \"wherefore art thou Romeo\"\n",
        "\n",
        "print(\"GREEDY SAMPLING\")\n",
        "\n",
        "predict(test_sentence, sampling_method='greedy')\n",
        "\n",
        "print(\"TEMPERATURE SAMPLING\")\n",
        "\n",
        "predict(test_sentence, sampling_method='temperature', temperature=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "d1c1e0f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GREEDY SAMPLING\n",
            "Input: where is my love\n",
            "Sampling: greedy (temp=0.8, k=40, p=0.9)\n",
            "Output: is my love the judgment fled\n",
            "\n",
            "TEMPERATURE SAMPLING\n",
            "Input: where is my love\n",
            "Sampling: temperature (temp=0.8, k=40, p=0.9)\n",
            "Output: is my love the judgment fled\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'is my love the judgment fled'"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_sentence = \"where is my love\"\n",
        "\n",
        "print(\"GREEDY SAMPLING\")\n",
        "\n",
        "predict(test_sentence, sampling_method='greedy')\n",
        "\n",
        "print(\"TEMPERATURE SAMPLING\")\n",
        "\n",
        "predict(test_sentence, sampling_method='temperature', temperature=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "fc39a8b4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GREEDY SAMPLING\n",
            "Input: you shall not pass\n",
            "Sampling: greedy (temp=0.8, k=40, p=0.9)\n",
            "Output: you pace forth the number let your sweet hue\n",
            "\n",
            "TEMPERATURE SAMPLING\n",
            "Input: you shall not pass\n",
            "Sampling: temperature (temp=0.8, k=40, p=0.9)\n",
            "Output: you pace forth the number happy you pace forth my verses tend\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'you pace forth the number happy you pace forth my verses tend'"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_sentence = \"you shall not pass\"\n",
        "\n",
        "print(\"GREEDY SAMPLING\")\n",
        "\n",
        "predict(test_sentence, sampling_method='greedy')\n",
        "\n",
        "print(\"TEMPERATURE SAMPLING\")\n",
        "\n",
        "predict(test_sentence, sampling_method='temperature', temperature=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08ca7647",
      "metadata": {},
      "source": [
        "The output looks poem like, but does have a tendency to repeat certain words. Sometime these repetition looks good but other times its predicting some words more frequently than others. Also a temperature of 0.8 or 1 os working better for the temperature sampling aproach"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90a218e6",
      "metadata": {},
      "source": [
        "### Inference\n",
        "\n",
        "Below we define generate sonnet function to generate a complete sonnet from a prompt\n",
        "\n",
        "`evaluate_line()`\n",
        "\n",
        "- Takes starting words\n",
        "- Generates next 10-12 words using transformer\n",
        "- Uses greedy or temperature sampling\n",
        "- Returns word IDs\n",
        "\n",
        "`predict_line()`\n",
        "\n",
        "- Calls evaluate_line() for word IDs\n",
        "- Converts IDs to text\n",
        "- Returns one line\n",
        "\n",
        "`generate_sonnet()`\n",
        "\n",
        "- Generates 14 lines using predict_line()\n",
        "- Continues from previous line's last words\n",
        "- Checks for repetition\n",
        "- Returns complete sonnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "c60b6d7d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_line(seed_text, max_length=12, temperature=1.0, sampling_method='temperature'):\n",
        "    \n",
        "    # Tokenize seed text\n",
        "    seed_tokens = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    \n",
        "    # Keep seed short to avoid repetition\n",
        "    seed_tokens = seed_tokens[-3:] if len(seed_tokens) > 3 else seed_tokens\n",
        "    \n",
        "    # Prepare encoder input\n",
        "    encoder_input = [START_TOKEN] + seed_tokens\n",
        "    encoder_input = tf.expand_dims(encoder_input, 0)\n",
        "    \n",
        "    # Decoder starts with START_TOKEN\n",
        "    decoder_input = tf.expand_dims([START_TOKEN], 0)\n",
        "    \n",
        "    generated_ids = []\n",
        "    \n",
        "    # Generate tokens one by one\n",
        "    for _ in range(max_length):\n",
        "        # Create masks\n",
        "        enc_padding_mask = create_padding_mask(encoder_input)\n",
        "        dec_padding_mask = create_padding_mask(encoder_input)\n",
        "        look_ahead_mask = create_look_ahead_mask(decoder_input)\n",
        "        dec_target_padding_mask = create_padding_mask(decoder_input)\n",
        "        combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "        \n",
        "        # Get predictions\n",
        "        predictions, _ = transformer(\n",
        "            encoder_input,\n",
        "            decoder_input,\n",
        "            training=False,\n",
        "            enc_padding_mask=enc_padding_mask,\n",
        "            look_ahead_mask=combined_mask,\n",
        "            dec_padding_mask=dec_padding_mask\n",
        "        )\n",
        "        \n",
        "        # Get last token predictions\n",
        "        predictions = predictions[:, -1, :]\n",
        "        \n",
        "        # Apply sampling strategy\n",
        "        if sampling_method == 'greedy':\n",
        "            predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "        else:  # temperature\n",
        "            scaled_predictions = predictions / temperature\n",
        "            predicted_id = tf.random.categorical(scaled_predictions, num_samples=1)\n",
        "            predicted_id = predicted_id[0]\n",
        "        \n",
        "        predicted_id = tf.cast(predicted_id, tf.int32)\n",
        "        \n",
        "        # Extract word ID\n",
        "        if predicted_id.shape.ndims > 0:\n",
        "            word_id = int(predicted_id.numpy()[0])\n",
        "        else:\n",
        "            word_id = int(predicted_id.numpy())\n",
        "        \n",
        "        # Stop conditions\n",
        "        if word_id == END_TOKEN:\n",
        "            break\n",
        "        \n",
        "        if word_id != START_TOKEN and word_id != 0:\n",
        "            word = tokenizer.index_word.get(word_id)\n",
        "            if word and word not in ['eol', '_eol_']:\n",
        "                generated_ids.append(word_id)\n",
        "        \n",
        "        # Update decoder input\n",
        "        predicted_id = tf.expand_dims(predicted_id, 0)\n",
        "        decoder_input = tf.concat([decoder_input, predicted_id], axis=-1)\n",
        "    \n",
        "    return generated_ids\n",
        "\n",
        "\n",
        "def predict_line(seed_text, temperature=1.0, sampling_method='temperature', max_length=12):\n",
        "    \n",
        "    word_ids = evaluate_line(seed_text, max_length, temperature, sampling_method)\n",
        "    \n",
        "    words = []\n",
        "    for word_id in word_ids:\n",
        "        word = tokenizer.index_word.get(word_id)\n",
        "        if word:\n",
        "            words.append(word)\n",
        "    \n",
        "    line = \" \".join(words).replace('comma', ',').strip()\n",
        "    return line\n",
        "\n",
        "\n",
        "def generate_sonnet(prompt, temperature=1.0, sampling_method='temperature', num_lines=14):\n",
        "    \n",
        "    print(f\"Generating {num_lines}-line sonnet from: '{prompt}'\")\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    sonnet_lines = [prompt]\n",
        "    print(f\"Line  1: {prompt}\")\n",
        "\n",
        "    retry_count = 0\n",
        "    max_retries = 50  # to prevent infinite loops\n",
        "    \n",
        "    while len(sonnet_lines) < num_lines and retry_count < max_retries:\n",
        "        line_num = len(sonnet_lines) + 1\n",
        "        \n",
        "        if len(sonnet_lines) > 1:\n",
        "            # Continue from last line (take last few words)\n",
        "            prev_words = sonnet_lines[-1].split()\n",
        "            if len(prev_words) >= 6:\n",
        "                seed = \" \".join(prev_words[-6:])\n",
        "            elif len(prev_words) >= 5:\n",
        "                seed = \" \".join(prev_words[-5:])                \n",
        "            elif len(prev_words) >= 4:\n",
        "                seed = \" \".join(prev_words[-4:])\n",
        "            elif len(prev_words) >= 3:\n",
        "                seed = \" \".join(prev_words[-3:])                                \n",
        "            elif len(prev_words) >= 2:\n",
        "                seed = \" \".join(prev_words[-2:])\n",
        "            elif prev_words:\n",
        "                seed = prev_words[-1]\n",
        "            else:\n",
        "                seed = prompt\n",
        "        else:\n",
        "            seed = prompt\n",
        "        \n",
        "        # Generate the line\n",
        "        try:\n",
        "            new_line = predict_line(\n",
        "                seed, \n",
        "                temperature=temperature,\n",
        "                sampling_method=sampling_method,\n",
        "                max_length=10\n",
        "            )\n",
        "            \n",
        "            # Quality checks\n",
        "            if not new_line or len(new_line.split()) < 3:\n",
        "                retry_count += 1\n",
        "                continue\n",
        "            \n",
        "            # Avoid exact repetition\n",
        "            if new_line in sonnet_lines or new_line in sonnet_lines[-1]:\n",
        "                retry_count += 1\n",
        "                continue\n",
        "            \n",
        "            # Avoid lines that are just the seed\n",
        "            if new_line == seed:\n",
        "                retry_count += 1\n",
        "                continue\n",
        "            \n",
        "            sonnet_lines.append(new_line)\n",
        "            print(f\"Line {line_num}: {new_line}\")\n",
        "            \n",
        "            retry_count = 0\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error generating line {line_num}: {e}\")\n",
        "            retry_count += 1\n",
        "            continue\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nGenerated {len(sonnet_lines)} lines\")\n",
        "    \n",
        "    return \"\\n\".join(sonnet_lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09a7b464",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating 14-line sonnet from: 'Shall I compare thee to a summer's day'\n",
            "\n",
            "\n",
            "Line  1: Shall I compare thee to a summer's day\n",
            "Line 2: spirit of youth winter's day\n",
            "Line 3: and barren rage of death's eternal barren thine day\n",
            "Line 4: of thine eye in thy view\n",
            "Line 5: in thy view is pleased to dote\n",
            "Line 6: times of view\n",
            "Line 7: of view is pleased to dote\n",
            "Line 8: in despite of view\n",
            "Line 9: in despite of view is pleased to dote\n",
            "Line 10: and your dote\n",
            "Line 11: and shows not half your world's of your pity is\n",
            "Line 12: is enough to cure and pity is enough to cure\n",
            "Line 13: and to cure me\n",
            "Line 14: it repair should prepare me\n",
            "======================================================================\n",
            "\n",
            "Generated 14 lines\n"
          ]
        }
      ],
      "source": [
        "# Basic usage - balanced style\n",
        "sonnet = generate_sonnet(\"Shall I compare thee to a summer's day\", sampling_method='temperature')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "438a3807",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating 14-line sonnet from: 'Shall I compare thee to a summer's day'\n",
            "\n",
            "\n",
            "Line  1: Shall I compare thee to a summer's day\n",
            "Line 2: spirit of youth to sullied night\n",
            "Line 3: theirs for a rainy morrow to walls of youth to\n",
            "Line 4: of youth to sullied will\n",
            "Line 5: my mind thus\n",
            "Line 6: forbear maketh with spirits untrue\n",
            "Line 7: thine ten there with thee\n",
            "Line 8: upon thee of her face\n",
            "Line 9: of her face the shore face\n",
            "Line 10: obsequious thou viewest right face the meadows conceit of meadows\n",
            "Line 11: of love there bred in thy offence this inconstant\n",
            "Line 12: swift dispatch in this inconstant stay\n",
            "Line 13: lies of this wards of stay\n",
            "Line 14: would make thing wards of trust\n",
            "======================================================================\n",
            "\n",
            "Generated 14 lines\n"
          ]
        }
      ],
      "source": [
        "sonnet = generate_sonnet(\"Shall I compare thee to a summer's day\", sampling_method='temperature')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "98f1ee2f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating 14-line sonnet from: 'Death be not proud'\n",
            "\n",
            "\n",
            "Line  1: Death be not proud\n",
            "Line 2: not slave which yet stern all vile despite thy proud\n",
            "Line 3: have thy scythe and\n",
            "Line 4: hence and make\n",
            "Line 5: and lovers physician\n",
            "Line 6: thee when therein show not are still these lovers grace\n",
            "Line 7: counterpart highmost days grow'st\n",
            "Line 8: denote days should find\n",
            "Line 9: hymn should find\n",
            "Line 10: from men shows stealth mayst find\n",
            "Line 11: mayst know prove promise kiss\n",
            "Line 12: nor prove the tender they would thy honouring to lust\n",
            "Line 13: to methods indirectly world's madding is proved\n",
            "Line 14: so preposterously be fairer chance of substance way\n",
            "======================================================================\n",
            "\n",
            "Generated 14 lines\n"
          ]
        }
      ],
      "source": [
        "sonnet = generate_sonnet(\"Death be not proud\", sampling_method='temperature', temperature=1.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "b7ee555a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating 14-line sonnet from: 'Fair youth beneath the'\n",
            "\n",
            "\n",
            "Line  1: Fair youth beneath the\n",
            "Line 2: triumphant no exchequer now\n",
            "Line 3: is but his time's but his present lives rebuked to\n",
            "Line 4: deep through hate whereon my content fame veil hope gentle\n",
            "Line 5: in their fame disgrace\n",
            "Line 6: soundless before their lines and filled sorrow his hymn\n",
            "Line 7: soul in polished form affords\n",
            "Line 8: of well refined each unto despise\n",
            "Line 9: in singleness the other lines mow\n",
            "Line 10: ambush of held\n",
            "Line 11: of bareness dote\n",
            "Line 12: is hath despite of liker\n",
            "Line 13: you look any while your painted counterfeit\n",
            "Line 14: being much liker counterfeit\n",
            "======================================================================\n",
            "\n",
            "Generated 14 lines\n"
          ]
        }
      ],
      "source": [
        "sonnet = generate_sonnet(\"Fair youth beneath the\", sampling_method='temperature', temperature=1.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "22ffc350",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating 14-line sonnet from: 'Fair youth beneath the'\n",
            "\n",
            "\n",
            "Line  1: Fair youth beneath the\n",
            "Line 2: , make the uphold level of every vulgar every book\n",
            "Line 3: too every selflove quite in every book\n",
            "Line 4: in every picture in every book\n",
            "Line 5: , this devise\n",
            "Line 6: largess some virtuous lie to me book\n",
            "Line 7: it were give even yours in wert book\n",
            "Line 8: in book touched depart book\n",
            "Line 9: behold these for lies with stay\n",
            "Line 10: man travel your coming stay\n",
            "Line 11: finding truest you maintain swear turns your canst world's deserves\n",
            "Line 12: look world's common view\n",
            "Line 13: doth view is pleased to grace their o'er their long\n",
            "Line 14: flower against chase thee entombed space that call despise which\n",
            "======================================================================\n",
            "\n",
            "Generated 14 lines\n"
          ]
        }
      ],
      "source": [
        "sonnet = generate_sonnet(\"Fair youth beneath the\", sampling_method='temperature', temperature=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40e43841",
      "metadata": {},
      "source": [
        "### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7ef7a3f",
      "metadata": {},
      "source": [
        "For sentence generation tasks using transformers, it is good to have a good amount of long sequences as training sets. We have tried limiting the ngrams to to those of only higher sequences (5 and above) and we did see a much higher accuracy (50%), However, the model outputted lines and sonnets that were less poem like. The smaller sequence length Ngrams helps the model learn the word play used in the shakespears sonnets and so including all the Ngrams up to 20 did help in giving out a more poem like output.\n",
        "\n",
        "The model performance could be made better if we had more text examples or increase the training corpus size. The accuracy started to plateau after 20 epochs coming up to only 18%. However, even with this the model performed relatively well, even if it repeats some words from time to time. This is something that can be solved if we had more vocabulary in our data which the model can use to predict more diverse words "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "info6106",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
